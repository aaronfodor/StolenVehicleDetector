@article{Attention-basedExtract,
 author = {Zbigniew Wojna, Alex Gorban, Dar-Shyang Lee, Kevin Murphy, Qian Yu, Yeqing Li and Julian Ibarz},
 title = {Attention-based Extraction of Structured Information from Street View Imagery},
 journal = {arXiv:1704.03549v4},
 year = {2017},
 }
 
@article{OrigamiNet,
 author = {Mohamed Yousef and Tom E. Bishop},
 title = {OrigamiNet: Weakly-Supervised, Segmentation-Free, One-Step, Full Page Text Recognition by learning to unfold},
 journal = {arXiv:2006.07491v1},
 year = {2020},
 }
 
@article{WPOD-NET,
 author = {Sergio Montazzolli Silva and Claudio Rosito Jung},
 title = {License Plate Detection and Recognition in Unconstrained Scenarios},
 journal = {ECCV 2018},
 year = {2018},
 }
 
@article{PadBlindSpot,
 author = {Bilal Alsallakh, Narine Kokhlikyan, Vivek Miglani, Jun Yuan and Orion Reblitz-Richardson},
 title = {MIND THE PAD â€“ CNNS CAN DEVELOP BLIND SPOTS},
 journal = {arXiv:2010.02178v1},
 year = {2020},
 }
 
@article{ResNet,
 author = {Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun},
 title = {Deep Residual Learning for Image Recognition},
 journal = {arXiv:1512.03385v1},
 year = {2015},
 }
 
@article{LSTM,
 author = {Sepp Hochreiter and Jurgen Schmidhuber},
 title = {LONG SHORT-TERM MEMORY},
 journal = {Neural Computation 9(8):1735-1780},
 year = {1997},
 }
 
@article{Hyperband,
 author = {Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh and Ameet Talwalkar},
 title = {Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization},
 journal = {arXiv:1603.06560v4},
 year = {2018},
 }
 
@article{Shift-Invariant,
 author = {Richard Zhang},
 title = {Making Convolutional Networks Shift-Invariant Again},
 journal = {arXiv:1904.11486v2},
 year = {2019},
 }
 
@article{SSD,
 author = {Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu and Alexander C. Berg},
 title = {SSD: Single Shot MultiBox Detector},
 journal = {arXiv:1512.02325v5},
 year = {2016},
 }
 
@article{YOLO9000,
 author = {Joseph Redmon and Ali Farhadi},
 title = {YOLO9000: Better, Faster, Stronger},
 journal = {arXiv:1612.08242v1},
 year = {2016},
 }
 
 @article{Adam,
 author = {Diederik P. Kingma and Jimmy Lei Ba},
 title = {ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION},
 journal = {arXiv:1412.6980v9},
 year = {2017},
 }

@inproceedings{CTC,
 author = {Alex Graves, Santiago Fernandez, Faustino Gomez and Jurgen Schmidhuber},
 year = {2001},
 title = {Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks},
 booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
 }
 
@misc{ScaleWordSeg,
 title = {Scale Space Technique for Word Segmentation in Handwritten Documents},
 author = {R. Manmatha and Nitin Srimal},
 howpublished = {Available at \url{http://ciir.cs.umass.edu/pubfiles/mm-27.pdf} (2021/04/24)}
}

@misc{PlatesMania,
 title = {PlatesMania.com},
 author = {},
 howpublished = {Available at \url{http://platesmania.com} (2021/04/22)}
}

@misc{WordBeamSearch,
 title = {Word Beam Search: A Connectionist Temporal Classification Decoding Algorithm},
 author = {Harald Scheidl, Stefan Fiel and Robert Sablatnig},
 howpublished = {Available at \url{https://repositum.tuwien.at/retrieve/1835} (2021/04/23)}
}

@misc{TfGrayscale,
 title = {TensorFlow's grayscale conversion},
 author = {TensorFlow},
 howpublished = {Available at \url{https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/ops/image_ops_impl.py#L2298-L2331} (2021/04/20)}
}

@misc{MLKitTextRecognition,
 title = {MLKit Text Recognition},
 author = {Google},
 howpublished = {Available at \url{https://developers.google.com/ml-kit/vision/text-recognition} (2021/04/23)}
}

@misc{YOLOv5,
 title = {Ultralytic's YOLOv5},
 author = {G. Jocher, A. Stoken, J. Borovec, NanoCode012, ChristopherSTAN, L. Changyu, Laughing, A. Hogan, lorenzomammana, tkianai, yxNONG, AlexWang1900, L. Diaconu, Marc, wanghaoyang0106, ml5ah, Doug, Hatovix, J. Poznanski, L. Y. , changyu98, P. Rai, R. Ferriday, T. Sullivan, W. Xinyu, YuriRibeiro, E. R. Claramunt, hopesala, pritul dave, and yzchen},
 howpublished = {Available at \url{https://github.com/ultralytics/yolov5} (2021/04/23)}
}

@misc{CTCexp,
  author       = {Harald Scheidl},
  title        = {An Intuitive Explanation of Connectionist Temporal Classification},
  howpublished    = {\url{https://bit.ly/3aUSS3t}}
  note = {Accessed: 2021-04-22}
}

 @article{CRAFT,
 author = {Youngmin Baek, Bado Lee, Dongyoon Han, Sangdoo Yun and Hwalsuk Lee},
 title = {Character Region Awareness for Text Detection},
 journal = {arXiv:1904.01941v1},
 year = {2019},
 }
 
@misc{Python,
 title = {Python programming language},
 author = {},
 howpublished = {Available at \url{https://www.python.org/about/} (2021/05/22)}
}

@misc{Kotlin,
 title = {Kotlin programming language},
 author = {},
 howpublished = {Available at \url{https://kotlinlang.org/} (2021/05/22)}
}

@misc{Ktor,
 title = {The Ktor Framework},
 author = {},
 howpublished = {Available at \url{https://ktor.io/} (2021/05/22)}
}

@misc{TensorFlowEager,
 title = {TensorFlow Eager execution},
 author = {},
 howpublished = {Available at \url{https://www.tensorflow.org/guide/eager} (2021/05/22)}
}

@misc{TensorFlowQuant,
 title = {TensorFlow Post-Training Quantization},
 author = {},
 howpublished = {Available at \url{https://www.tensorflow.org/guide/eager} (2021/05/22)}
}

@misc{Protobuf,
 title = {Protocol Buffers},
 author = {},
 howpublished = {Available at \url{https://www.tensorflow.org/lite/performance/post_training_quantization} (2021/05/22)}
}

@misc{Flatbuf,
 title = Flatbuffers},
 author = {},
 howpublished = {Available at \url{https://google.github.io/flatbuffers/} (2021/05/22)}
}

@misc{ProtobufVsFlatbuf,
 title = JSON vs Protocol Buffers vs Flatbuffers},
 author = {Kartik Khare},
 howpublished = {Available at \url{https://codeburst.io/json-vs-protocol-buffers-vs-flatbuffers-a4247f8bda6f} (2021/05/22)}
}