{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yhzxsJb3dpWq",
        "iCNYAaC7w6N8",
        "Fs-6YZo3x5vO"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQCnYPVDrsgx",
        "colab_type": "text"
      },
      "source": [
        "# Model training notebook\n",
        ">This notebook uses Tensorflow Object Detection API to train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq",
        "colab_type": "text"
      },
      "source": [
        "## 1. Prepare the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwWSNonPvMwj",
        "colab_type": "text"
      },
      "source": [
        "### Import every dependency used\n",
        ">Restart runtime after this command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP2AGPx1fZbb",
        "colab_type": "code",
        "outputId": "599452f4-0acb-43ec-a93d-89912a91d249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!python -m pip install numpy==1.17.4\n",
        "!python -m pip install --upgrade tf-slim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.17.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0MB 74.6MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.4\n",
            "    Uninstalling numpy-1.18.4:\n",
            "      Successfully uninstalled numpy-1.18.4\n",
            "Successfully installed numpy-1.17.4\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf-slim) (1.12.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab_type": "code",
        "outputId": "73a867fe-05ad-41ef-8287-9eecf3dbe976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import zipfile\n",
        "import shutil\n",
        "import re\n",
        "import numpy as np\n",
        "tf.__version__\n",
        "np.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.17.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRsB06WbPKsW",
        "colab_type": "code",
        "outputId": "53fe5428-5911-496f-955c-f9bf6031c002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May 27 17:07:57 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHXNeWqrwXvd",
        "colab_type": "text"
      },
      "source": [
        "### Define paths\n",
        "\n",
        ">Paths defined to work remotely on google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGThu1Y2P3Yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rootPath = '/content/drive/My Drive/Machine Learning/License plate detection'\n",
        "dataPath = rootPath + '/data'\n",
        "savedPath = rootPath + '/saved'\n",
        "modelsPath = savedPath + '/models'\n",
        "\n",
        "localPath = '/content'\n",
        "localDataPath = localPath + '/data'\n",
        "modelDir = localPath + '/training'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkvqHD8hwago",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive to this Notebook instance\n",
        ">As the dataset has been prepared previously and updated to Google Drive, the model building and training process will be done there, not locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaWYrZfzQN0b",
        "colab_type": "code",
        "outputId": "6bd9a82e-292c-4bc7-bbe9-69ff68067fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "os.chdir(localPath)\n",
        "# Show current directory\n",
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz8DYww8vJqv",
        "colab_type": "text"
      },
      "source": [
        "### Prepare and test Object Detection module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab_type": "code",
        "outputId": "c8949837-08d5-4596-d1f2-36645c6ac8cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%cd /content\n",
        "\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!python object_detection/builders/model_builder_test.py\n",
        "\n",
        "%cd /content\n",
        "repo_url = 'https://github.com/Tony607/object_detection_demo'\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144433 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/models/research\n",
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n",
            "/content\n",
            "Cloning into 'object_detection_demo'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Total 124 (delta 0), reused 0 (delta 0), pack-reused 124\u001b[K\n",
            "Receiving objects: 100% (124/124), 11.16 MiB | 29.68 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/object_detection_demo\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKarz_2exv8j",
        "colab_type": "text"
      },
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcShChmNxxFS",
        "colab_type": "text"
      },
      "source": [
        "### Choose a pre-trained model\n",
        "\n",
        ">The model used for this project is `ssd_mobilenet_v3_large_coco`.\n",
        "Other models are available [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models).\n",
        ">Real time inference is necessary, so a model with good inference speed (`ms`) needed to be chosen with a relativly high `mAP` on COCO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "067U-tIGlji4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training steps\n",
        "num_steps = 90000\n",
        "\n",
        "# Number of evaluation steps\n",
        "num_eval_steps = 1000\n",
        "\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05n16DtExXtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Models to work with\n",
        "MODELS_CONFIG = {\n",
        "\n",
        "    'ssd_quantized_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_quantized_300x300_coco.config',\n",
        "        'batch_size': 32,\n",
        "    },\n",
        "\n",
        "    'ssdlite_mobilenet_v2': {\n",
        "        'model_name': 'ssdlite_mobilenet_v2_coco_2018_05_09',\n",
        "        'pipeline_file': 'ssdlite_mobilenet_v2_coco.config',\n",
        "        'batch_size': 32,\n",
        "    },\n",
        "\n",
        "    'ssd_mobilenet_v2_oid': {\n",
        "        'model_name': 'ssd_mobilenet_v2_oid_v4_2018_12_12',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_oid_v4.config',\n",
        "        'batch_size': 32,\n",
        "    },\n",
        "\n",
        "    'ssd_mobilenet_v3_small_coco': {\n",
        "        'model_name': 'ssd_mobilenet_v3_small_coco_2019_08_14',\n",
        "        'pipeline_file': 'ssdlite_mobilenet_v3_small_320x320_coco.config',\n",
        "        'batch_size': 32,\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selectedModel = 'ssd_mobilenet_v3_small_coco'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Cy3YIhzTtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Name of the object detection model to use\n",
        "MODEL = MODELS_CONFIG[selectedModel]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API\n",
        "pipeline_file = MODELS_CONFIG[selectedModel]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colab's Tesla K80 GPU memory for selected model\n",
        "batch_size = MODELS_CONFIG[selectedModel]['batch_size']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8",
        "colab_type": "text"
      },
      "source": [
        "## 3. Optional: download base model\n",
        ">Download the selected model in the MODELS_CONFIG file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehahEt6Lz_kF",
        "colab_type": "text"
      },
      "source": [
        "### Check downloaded model content\n",
        ">This is the directory of the \"fine_tune_checkpoint\" that is used in the config file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab_type": "code",
        "outputId": "a447f317-05db-4b29-e115-2573f5479f5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 131M\n",
            "drwxr-x---  3 345018 89939 4.0K Dec 12  2018 .\n",
            "drwxr-xr-x 63 root   root  4.0K May 25 16:32 ..\n",
            "-rw-r-----  1 345018 89939   77 Dec 12  2018 checkpoint\n",
            "-rw-r-----  1 345018 89939  64M Dec 12  2018 frozen_inference_graph.pb\n",
            "-rw-r-----  1 345018 89939  56M Dec 12  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r-----  1 345018 89939  14K Dec 12  2018 model.ckpt.index\n",
            "-rw-r-----  1 345018 89939  12M Dec 12  2018 model.ckpt.meta\n",
            "-rw-r-----  1 345018 89939 4.2K Dec 12  2018 pipeline.config\n",
            "drwxr-x---  3 345018 89939 4.0K Dec 12  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab_type": "code",
        "outputId": "5697acd2-9efb-42b6-8156-aeb7b0162461",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipelineFilePath = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "assert os.path.isfile(pipelineFilePath), '`{}` not exist'.format(pipelineFilePath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzPTd8MQlCiq",
        "colab_type": "text"
      },
      "source": [
        "## 4. Optional: import saved model\n",
        ">If a previously saved model is selected to work with. The `zip` file is placed on Google Drive, but working there would be slow so needs to be extracted locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svL2kLXPlBiM",
        "colab_type": "code",
        "outputId": "90526390-9604-40bf-eb46-b361abeb377d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Name of the object detection model to load\n",
        "modelToLoad = 'ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training'\n",
        "\n",
        "modelDir = localPath + '/' + 'training'\n",
        "pipelineFilePath = modelDir + '/' + modelToLoad + '/' + 'pipeline.config'\n",
        "\n",
        "os.chdir(localPath)\n",
        "\n",
        "if (os.path.exists(modelDir)):\n",
        "  shutil.rmtree(modelDir)\n",
        "\n",
        "os.mkdir(modelDir)\n",
        "os.chdir(modelDir)\n",
        "\n",
        "# Load the frozen model that is needed for inference\n",
        "# Run it only when the model is not yet extracted \n",
        "zipRef = zipfile.ZipFile(modelsPath + '/' + modelToLoad + '.zip', 'r')\n",
        "zipRef.extractall(modelDir + '/')\n",
        "zipRef.close()\n",
        "modelDir = localPath + '/' + 'training' + '/' + modelToLoad\n",
        "print('Model extraction successful')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model extraction successful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs-6YZo3x5vO",
        "colab_type": "text"
      },
      "source": [
        "## 5. Dataset preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLFHdyO-x6yS",
        "colab_type": "text"
      },
      "source": [
        "### Extract `zip` dataset locally\n",
        ">To access the dataset. The `zip` file is placed on Google Drive, but working there would be slow so needs to be extracted locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fbzspE0Qdw2",
        "colab_type": "code",
        "outputId": "f1d19705-bc93-411b-998b-0603d3bf1ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Run it only when the dataset is not yet extracted \n",
        "zipRef = zipfile.ZipFile(dataPath + \"/datasetRecords.zip\", 'r')\n",
        "zipRef.extractall(localDataPath)\n",
        "zipRef.close()\n",
        "print('Dataset extraction successful')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset extraction successful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_record_fname = '/content/data/trainDataset.tfrecord-?????-of-00010'\n",
        "validation_record_fname = '/content/data/validationDataset.tfrecord-?????-of-00001'\n",
        "test_record_fname = '/content/data/testDataset.tfrecord-?????-of-00001'\n",
        "label_map_pbtxt_fname = '/content/data/classes.pbtxt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD",
        "colab_type": "text"
      },
      "source": [
        "## 6. Modify configuration file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i8Z2pugLOUf",
        "colab_type": "text"
      },
      "source": [
        "####Optional: Edit configuration file\n",
        ">Change config file based on selected model samples [here](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs).\n",
        ">\n",
        ">Add path to `tfrecod` files and to the `txt` file. Teaching parameters can be selected here (class number, batch size). Hyperparameters (augmentation, batch dropout, batch normalization, etc.) can be tuned here too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0oBwqzkO_Ag",
        "colab_type": "code",
        "outputId": "d3aea6bf-2aef-4573-b2ce-5516cc6e2a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(pipelineFilePath)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O46kfvW9LWwD",
        "colab_type": "code",
        "outputId": "f7f8783b-87b9-4922-bc0a-626824eaee71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%%writefile {pipelineFilePath}\n",
        "\n",
        "# SSDLite with Mobilenet v3 small feature extractor.\n",
        "# Trained on COCO14, initialized from scratch.\n",
        "# TPU-compatible.\n",
        "# Users should configure the fine_tune_checkpoint field in the train config as\n",
        "# well as the label_map_path and input_path fields in the train_input_reader and\n",
        "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
        "# should be configured.\n",
        "\n",
        "model {\n",
        "  ssd {\n",
        "    inplace_batchnorm_update: true\n",
        "    freeze_batchnorm: false\n",
        "    #change num_classes\n",
        "    num_classes: 3\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "        use_matmul_gather: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    encode_background_as_zeros: true\n",
        "    anchor_generator {\n",
        "      ssd_anchor_generator {\n",
        "        num_layers: 6\n",
        "        min_scale: 0.2\n",
        "        max_scale: 0.95\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        aspect_ratios: 3.0\n",
        "        aspect_ratios: 0.3333\n",
        "      }\n",
        "    }\n",
        "    image_resizer {\n",
        "      fixed_shape_resizer {\n",
        "        height: 320\n",
        "        width: 320\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      convolutional_box_predictor {\n",
        "        min_depth: 0\n",
        "        max_depth: 0\n",
        "        num_layers_before_predictor: 0\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 0.8\n",
        "        kernel_size: 3\n",
        "        use_depthwise: true\n",
        "        box_code_size: 4\n",
        "        apply_sigmoid_to_scores: false\n",
        "        class_prediction_bias_init: -4.6\n",
        "        conv_hyperparams {\n",
        "          activation: RELU_6,\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.00004\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            random_normal_initializer {\n",
        "              stddev: 0.03\n",
        "              mean: 0.0\n",
        "            }\n",
        "          }\n",
        "          batch_norm {\n",
        "            train: true,\n",
        "            scale: true,\n",
        "            center: true,\n",
        "            decay: 0.97,\n",
        "            epsilon: 0.001,\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'ssd_mobilenet_v3_small'\n",
        "      min_depth: 16\n",
        "      depth_multiplier: 1.0\n",
        "      use_depthwise: true\n",
        "      conv_hyperparams {\n",
        "        activation: RELU_6,\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            weight: 0.00004\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            stddev: 0.03\n",
        "            mean: 0.0\n",
        "          }\n",
        "        }\n",
        "        batch_norm {\n",
        "          train: true,\n",
        "          scale: true,\n",
        "          center: true,\n",
        "          decay: 0.97,\n",
        "          epsilon: 0.001,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    loss {\n",
        "      classification_loss {\n",
        "        weighted_sigmoid {\n",
        "        }\n",
        "      }\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      hard_example_miner {\n",
        "       num_hard_examples: 3000\n",
        "        iou_threshold: 0.99\n",
        "        loss_type: CLASSIFICATION\n",
        "        max_negatives_per_positive: 3\n",
        "        min_negatives_per_image: 3\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    normalize_loc_loss_by_codesize: true\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 1e-8\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 100\n",
        "        use_static_shapes: true\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  #change batch_size\n",
        "  batch_size: 32\n",
        "  sync_replicas: true\n",
        "  startup_delay_steps: 0\n",
        "  replicas_to_aggregate: 32\n",
        "  #change num_steps\n",
        "  num_steps: 90000\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    ssd_random_crop {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    random_adjust_contrast {\n",
        "    }\n",
        "  }\n",
        "  optimizer {\n",
        "    adam_optimizer: {\n",
        "      learning_rate: {\n",
        "        constant_learning_rate {\n",
        "          learning_rate: 0.00004\n",
        "        }\n",
        "      #  cosine_decay_learning_rate {\n",
        "      #    learning_rate_base: 0.00004\n",
        "      #    #change total_steps\n",
        "      #    total_steps: 40000\n",
        "      #    warmup_learning_rate: 0.00001\n",
        "      #    #change warmup_steps to include 1-2 epoch(s)\n",
        "      #    warmup_steps: 1500\n",
        "      #  }\n",
        "      }\n",
        "    }\n",
        "    use_moving_average: false\n",
        "  }\n",
        "  #Use it when you use a starter model\n",
        "  #fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
        "  #Use it when you continue your model's training\n",
        "  fine_tune_checkpoint: \"/content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-80000\"\n",
        "  from_detection_checkpoint: true\n",
        "  load_all_detection_checkpoint_vars: true\n",
        "  #change max_number_of_boxes\n",
        "  max_number_of_boxes: 100\n",
        "  unpad_groundtruth_tensors: false\n",
        "  freeze_variables: \".*FeatureExtractor*.\"\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    #change input_path\n",
        "    input_path: \"/content/data/trainDataset.tfrecord-?????-of-00010\"\n",
        "  }\n",
        "  #change label_map_path\n",
        "  label_map_path: \"/content/data/classes.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  #change num_examples\n",
        "  num_examples: 1000\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    #change input_path\n",
        "    input_path: \"/content/data/testDataset.tfrecord-?????-of-00001\"\n",
        "  }\n",
        "  #change label_map_path\n",
        "  label_map_path: \"/content/data/classes.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab_type": "code",
        "outputId": "202a4328-8d2f-4572-b835-84178a590473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!cat {pipelineFilePath}"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# SSDLite with Mobilenet v3 small feature extractor.\n",
            "# Trained on COCO14, initialized from scratch.\n",
            "# TPU-compatible.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "    #change num_classes\n",
            "    num_classes: 3\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 320\n",
            "        width: 320\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 3\n",
            "        use_depthwise: true\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        class_prediction_bias_init: -4.6\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.97,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v3_small'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      use_depthwise: true\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.97,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "       num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "        use_static_shapes: true\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  #change batch_size\n",
            "  batch_size: 32\n",
            "  sync_replicas: true\n",
            "  startup_delay_steps: 0\n",
            "  replicas_to_aggregate: 32\n",
            "  #change num_steps\n",
            "  num_steps: 90000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_adjust_contrast {\n",
            "    }\n",
            "  }\n",
            "  optimizer {\n",
            "    adam_optimizer: {\n",
            "      learning_rate: {\n",
            "        constant_learning_rate {\n",
            "          learning_rate: 0.00004\n",
            "        }\n",
            "      #  cosine_decay_learning_rate {\n",
            "      #    learning_rate_base: 0.00004\n",
            "      #    #change total_steps\n",
            "      #    total_steps: 40000\n",
            "      #    warmup_learning_rate: 0.00001\n",
            "      #    #change warmup_steps to include 1-2 epoch(s)\n",
            "      #    warmup_steps: 1500\n",
            "      #  }\n",
            "      }\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  #Use it when you use a starter model\n",
            "  #fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  #Use it when you continue your model's training\n",
            "  fine_tune_checkpoint: \"/content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-80000\"\n",
            "  from_detection_checkpoint: true\n",
            "  load_all_detection_checkpoint_vars: true\n",
            "  #change max_number_of_boxes\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "  freeze_variables: \".*FeatureExtractor*.\"\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    #change input_path\n",
            "    input_path: \"/content/data/trainDataset.tfrecord-?????-of-00010\"\n",
            "  }\n",
            "  #change label_map_path\n",
            "  label_map_path: \"/content/data/classes.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  #change num_examples\n",
            "  num_examples: 1000\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    #change input_path\n",
            "    input_path: \"/content/data/testDataset.tfrecord-?????-of-00001\"\n",
            "  }\n",
            "  #change label_map_path\n",
            "  label_map_path: \"/content/data/classes.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLumi7afLet1",
        "colab_type": "text"
      },
      "source": [
        "### Optional: remove previous local model output directory to fresh start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {modelDir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF",
        "colab_type": "text"
      },
      "source": [
        "## 7. Run Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2PZs-mSCmO",
        "colab_type": "code",
        "outputId": "2a6d3d1c-aec5-4780-dc25-311d37ed9ed6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "os.chdir(localPath)\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-27 17:17:52--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 3.229.170.137, 54.84.72.55, 18.214.118.253, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|3.229.170.137|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab   5%[>                   ] 694.67K  3.38MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  35.2MB/s    in 0.4s    \n",
            "\n",
            "2020-05-27 17:17:52 (35.2 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = modelDir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp",
        "colab_type": "text"
      },
      "source": [
        "### Get Tensorboard link\n",
        ">Tensorboard magic: re-run field if an error occured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhPT9iPSJ6T",
        "colab_type": "code",
        "outputId": "e4ebbd7b-4ccf-4afc-c6f9-a10c698697d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://30c419eb.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9",
        "colab_type": "text"
      },
      "source": [
        "## 8. Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4YeEkslnL52",
        "colab_type": "text"
      },
      "source": [
        "### Move pipeline file to the train folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udLcg_xzeCgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs(modelDir, exist_ok=True)\n",
        "shutil.copyfile(pipelineFilePath, modelDir + '/pipeline.config')\n",
        "pipelineFilePath = modelDir + '/pipeline.config'\n",
        "print(pipelineFilePath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCQSTWLh239F",
        "colab_type": "text"
      },
      "source": [
        "### Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab_type": "code",
        "outputId": "37209a17-839a-4695-e859-c34a03646f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipelineFilePath} \\\n",
        "    --model_dir={modelDir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0527 17:23:25.317433 140028679079808 model_lib.py:717] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 90000\n",
            "I0527 17:23:25.317617 140028679079808 config_util.py:523] Maybe overwriting train_steps: 90000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0527 17:23:25.317689 140028679079808 config_util.py:523] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0527 17:23:25.317764 140028679079808 config_util.py:523] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0527 17:23:25.317818 140028679079808 config_util.py:523] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0527 17:23:25.317889 140028679079808 config_util.py:523] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0527 17:23:25.317959 140028679079808 config_util.py:533] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0527 17:23:25.318867 140028679079808 model_lib.py:733] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0527 17:23:25.318958 140028679079808 model_lib.py:768] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5aa4826a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0527 17:23:25.319319 140028679079808 estimator.py:212] Using config: {'_model_dir': '/content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5aa4826a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f5a8a790d08>) includes params argument, but params are not passed to Estimator.\n",
            "W0527 17:23:25.319483 140028679079808 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f5a8a790d08>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0527 17:23:25.320101 140028679079808 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0527 17:23:25.320258 140028679079808 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0527 17:23:25.320440 140028679079808 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0527 17:23:25.335838 140028679079808 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 10 to match input file shards.\n",
            "W0527 17:23:25.365975 140028679079808 dataset_builder.py:84] num_readers has been reduced to 10 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0527 17:23:25.371038 140028679079808 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0527 17:23:25.371172 140028679079808 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5a8a71d7f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0527 17:23:25.418449 140028679079808 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5a8a71d7f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "2020-05-27 17:23:25.447098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-27 17:23:25.459642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:25.460221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-27 17:23:25.460471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-27 17:23:25.461997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-27 17:23:25.463645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-27 17:23:25.464007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-27 17:23:25.469642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-27 17:23:25.489512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-27 17:23:25.496325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-27 17:23:25.496558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:25.497261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:25.497801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f5aafbf4378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0527 17:23:25.638188 140028679079808 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f5aafbf4378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0527 17:23:25.641316 140028679079808 deprecation.py:323] From /content/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0527 17:23:25.649862 140028679079808 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:198: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0527 17:23:25.717045 140028679079808 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:198: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0527 17:23:26.408583 140028679079808 deprecation.py:323] From /content/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:174: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W0527 17:23:26.727464 140028679079808 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:174: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0527 17:23:26.741400 140028679079808 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0527 17:23:26.754781 140028679079808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:23:28.819683 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:23:28.901469 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:23:28.983052 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:23:29.069628 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:23:29.155388 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:23:29.238631 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "W0527 17:23:29.446774 140028679079808 variables_helper.py:164] Variable [global_step] is not available in checkpoint\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0527 17:23:38.340294 140028679079808 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0527 17:23:38.341470 140028679079808 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0527 17:23:40.893945 140028679079808 monitored_session.py:240] Graph was finalized.\n",
            "2020-05-27 17:23:40.992766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-05-27 17:23:40.993278: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14a79c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-27 17:23:40.993319: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-27 17:23:41.127309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:41.128036: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14a7800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-27 17:23:41.128071: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-05-27 17:23:41.129406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:41.130018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-27 17:23:41.130103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-27 17:23:41.130121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-27 17:23:41.130134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-27 17:23:41.130149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-27 17:23:41.130163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-27 17:23:41.130177: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-27 17:23:41.130192: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-27 17:23:41.130280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:41.130925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:41.131479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-27 17:23:41.134789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-27 17:23:41.138949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-27 17:23:41.138980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-27 17:23:41.138988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-27 17:23:41.142195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:41.146331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:41.146940: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-27 17:23:41.146980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-80000\n",
            "I0527 17:23:41.149188 140028679079808 saver.py:1284] Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-80000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0527 17:23:48.351674 140028679079808 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0527 17:23:48.995882 140028679079808 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0527 17:23:49.263368 140028679079808 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 80000 into /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt.\n",
            "I0527 17:23:56.278660 140028679079808 basic_session_run_hooks.py:606] Saving checkpoints for 80000 into /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt.\n",
            "2020-05-27 17:24:03.344097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-27 17:24:07.365975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 2.3559313, step = 80000\n",
            "I0527 17:24:12.243211 140028679079808 basic_session_run_hooks.py:262] loss = 2.3559313, step = 80000\n",
            "INFO:tensorflow:global_step/sec: 2.43887\n",
            "I0527 17:24:53.244038 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.43887\n",
            "INFO:tensorflow:loss = 2.6508274, step = 80100 (41.004 sec)\n",
            "I0527 17:24:53.246741 140028679079808 basic_session_run_hooks.py:260] loss = 2.6508274, step = 80100 (41.004 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.68216\n",
            "I0527 17:25:30.527294 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.68216\n",
            "INFO:tensorflow:loss = 1.9450494, step = 80200 (37.283 sec)\n",
            "I0527 17:25:30.529684 140028679079808 basic_session_run_hooks.py:260] loss = 1.9450494, step = 80200 (37.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.61514\n",
            "I0527 17:26:08.766105 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.61514\n",
            "INFO:tensorflow:loss = 2.0221908, step = 80300 (38.238 sec)\n",
            "I0527 17:26:08.768005 140028679079808 basic_session_run_hooks.py:260] loss = 2.0221908, step = 80300 (38.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.56592\n",
            "I0527 17:26:47.738562 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.56592\n",
            "INFO:tensorflow:loss = 2.1114109, step = 80400 (38.972 sec)\n",
            "I0527 17:26:47.739803 140028679079808 basic_session_run_hooks.py:260] loss = 2.1114109, step = 80400 (38.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.57142\n",
            "I0527 17:27:26.627431 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.57142\n",
            "INFO:tensorflow:loss = 2.2238772, step = 80500 (38.905 sec)\n",
            "I0527 17:27:26.645224 140028679079808 basic_session_run_hooks.py:260] loss = 2.2238772, step = 80500 (38.905 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35258\n",
            "I0527 17:28:09.133922 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.35258\n",
            "INFO:tensorflow:loss = 2.2685144, step = 80600 (42.504 sec)\n",
            "I0527 17:28:09.148840 140028679079808 basic_session_run_hooks.py:260] loss = 2.2685144, step = 80600 (42.504 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.40745\n",
            "I0527 17:28:50.671722 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.40745\n",
            "INFO:tensorflow:loss = 2.0581706, step = 80700 (41.525 sec)\n",
            "I0527 17:28:50.673696 140028679079808 basic_session_run_hooks.py:260] loss = 2.0581706, step = 80700 (41.525 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.50171\n",
            "I0527 17:29:30.644392 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.50171\n",
            "INFO:tensorflow:loss = 2.2293894, step = 80800 (39.984 sec)\n",
            "I0527 17:29:30.658021 140028679079808 basic_session_run_hooks.py:260] loss = 2.2293894, step = 80800 (39.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.49116\n",
            "I0527 17:30:10.786317 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.49116\n",
            "INFO:tensorflow:loss = 2.1540601, step = 80900 (40.135 sec)\n",
            "I0527 17:30:10.793386 140028679079808 basic_session_run_hooks.py:260] loss = 2.1540601, step = 80900 (40.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.54999\n",
            "I0527 17:30:50.002017 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.54999\n",
            "INFO:tensorflow:loss = 1.8108727, step = 81000 (39.210 sec)\n",
            "I0527 17:30:50.003429 140028679079808 basic_session_run_hooks.py:260] loss = 1.8108727, step = 81000 (39.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.61667\n",
            "I0527 17:31:28.218443 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.61667\n",
            "INFO:tensorflow:loss = 1.9732243, step = 81100 (38.216 sec)\n",
            "I0527 17:31:28.219591 140028679079808 basic_session_run_hooks.py:260] loss = 1.9732243, step = 81100 (38.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.69125\n",
            "I0527 17:32:05.382373 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.69125\n",
            "INFO:tensorflow:loss = 1.7973307, step = 81200 (37.174 sec)\n",
            "I0527 17:32:05.393937 140028679079808 basic_session_run_hooks.py:260] loss = 1.7973307, step = 81200 (37.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.60032\n",
            "I0527 17:32:43.832851 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.60032\n",
            "INFO:tensorflow:loss = 2.2676609, step = 81300 (38.441 sec)\n",
            "I0527 17:32:43.834764 140028679079808 basic_session_run_hooks.py:260] loss = 2.2676609, step = 81300 (38.441 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.43812\n",
            "I0527 17:33:24.848025 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.43812\n",
            "INFO:tensorflow:loss = 1.984503, step = 81400 (41.020 sec)\n",
            "I0527 17:33:24.854488 140028679079808 basic_session_run_hooks.py:260] loss = 1.984503, step = 81400 (41.020 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 81488 into /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt.\n",
            "I0527 17:33:57.941403 140028679079808 basic_session_run_hooks.py:606] Saving checkpoints for 81488 into /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0527 17:33:57.992856 140028679079808 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5a28057908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0527 17:34:00.182015 140028679079808 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5a28057908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f5a2f49c9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0527 17:34:00.332292 140028679079808 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f5a2f49c9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0527 17:34:00.750378 140028679079808 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:34:02.798860 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:34:02.872235 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:34:02.944696 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:34:03.018240 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:34:03.095637 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:34:03.166440 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:828: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0527 17:34:03.716998 140028679079808 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:828: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0527 17:34:03.911865 140028679079808 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0527 17:34:04.417098 140028679079808 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-05-27T17:34:04Z\n",
            "I0527 17:34:04.433362 140028679079808 evaluation.py:255] Starting evaluation at 2020-05-27T17:34:04Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0527 17:34:04.852702 140028679079808 monitored_session.py:240] Graph was finalized.\n",
            "2020-05-27 17:34:04.853721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:34:04.854277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-27 17:34:04.854376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-27 17:34:04.854408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-27 17:34:04.854422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-27 17:34:04.854439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-27 17:34:04.854453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-27 17:34:04.854468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-27 17:34:04.854482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-27 17:34:04.854591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:34:04.855210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:34:04.855741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-27 17:34:04.855787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-27 17:34:04.855799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-27 17:34:04.855807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-27 17:34:04.855928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:34:04.856564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:34:04.857060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-81488\n",
            "I0527 17:34:04.858159 140028679079808 saver.py:1284] Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-81488\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0527 17:34:05.759193 140028679079808 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0527 17:34:05.883637 140028679079808 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1440 images.\n",
            "I0527 17:35:23.613704 140024825771776 coco_evaluation.py:236] Performing evaluation on 1440 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0527 17:35:23.622226 140024825771776 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.12s)\n",
            "I0527 17:35:23.746709 140024825771776 coco_tools.py:137] DONE (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=13.67s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.85s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.505\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.294\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.423\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n",
            "INFO:tensorflow:Finished evaluation at 2020-05-27-17:35:40\n",
            "I0527 17:35:40.141879 140028679079808 evaluation.py:275] Finished evaluation at 2020-05-27-17:35:40\n",
            "INFO:tensorflow:Saving dict for global step 81488: DetectionBoxes_Precision/mAP = 0.29625162, DetectionBoxes_Precision/mAP (large) = 0.42155772, DetectionBoxes_Precision/mAP (medium) = 0.08214585, DetectionBoxes_Precision/mAP (small) = 0.00045042468, DetectionBoxes_Precision/mAP@.50IOU = 0.504579, DetectionBoxes_Precision/mAP@.75IOU = 0.29364488, DetectionBoxes_Recall/AR@1 = 0.29534122, DetectionBoxes_Recall/AR@10 = 0.4232678, DetectionBoxes_Recall/AR@100 = 0.46023065, DetectionBoxes_Recall/AR@100 (large) = 0.6101871, DetectionBoxes_Recall/AR@100 (medium) = 0.22956394, DetectionBoxes_Recall/AR@100 (small) = 0.013601734, Loss/classification_loss = 1.7713321, Loss/localization_loss = 0.21067277, Loss/regularization_loss = 0.029949257, Loss/total_loss = 2.0119526, global_step = 81488, learning_rate = 4e-05, loss = 2.0119526\n",
            "I0527 17:35:40.142219 140028679079808 estimator.py:2049] Saving dict for global step 81488: DetectionBoxes_Precision/mAP = 0.29625162, DetectionBoxes_Precision/mAP (large) = 0.42155772, DetectionBoxes_Precision/mAP (medium) = 0.08214585, DetectionBoxes_Precision/mAP (small) = 0.00045042468, DetectionBoxes_Precision/mAP@.50IOU = 0.504579, DetectionBoxes_Precision/mAP@.75IOU = 0.29364488, DetectionBoxes_Recall/AR@1 = 0.29534122, DetectionBoxes_Recall/AR@10 = 0.4232678, DetectionBoxes_Recall/AR@100 = 0.46023065, DetectionBoxes_Recall/AR@100 (large) = 0.6101871, DetectionBoxes_Recall/AR@100 (medium) = 0.22956394, DetectionBoxes_Recall/AR@100 (small) = 0.013601734, Loss/classification_loss = 1.7713321, Loss/localization_loss = 0.21067277, Loss/regularization_loss = 0.029949257, Loss/total_loss = 2.0119526, global_step = 81488, learning_rate = 4e-05, loss = 2.0119526\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 81488: /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-81488\n",
            "I0527 17:35:41.111853 140028679079808 estimator.py:2109] Saving 'checkpoint_path' summary for global step 81488: /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-81488\n",
            "INFO:tensorflow:global_step/sec: 0.715139\n",
            "I0527 17:35:44.681012 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 0.715139\n",
            "INFO:tensorflow:loss = 2.078465, step = 81500 (139.832 sec)\n",
            "I0527 17:35:44.686877 140028679079808 basic_session_run_hooks.py:260] loss = 2.078465, step = 81500 (139.832 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.82016\n",
            "I0527 17:36:20.139895 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.82016\n",
            "INFO:tensorflow:loss = 2.1101046, step = 81600 (35.455 sec)\n",
            "I0527 17:36:20.141837 140028679079808 basic_session_run_hooks.py:260] loss = 2.1101046, step = 81600 (35.455 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.87941\n",
            "I0527 17:36:54.869206 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.87941\n",
            "INFO:tensorflow:loss = 2.6564026, step = 81700 (34.736 sec)\n",
            "I0527 17:36:54.877975 140028679079808 basic_session_run_hooks.py:260] loss = 2.6564026, step = 81700 (34.736 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.88063\n",
            "I0527 17:37:29.583783 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.88063\n",
            "INFO:tensorflow:loss = 2.0457356, step = 81800 (34.707 sec)\n",
            "I0527 17:37:29.584975 140028679079808 basic_session_run_hooks.py:260] loss = 2.0457356, step = 81800 (34.707 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.78538\n",
            "I0527 17:38:05.485476 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.78538\n",
            "INFO:tensorflow:loss = 2.2154157, step = 81900 (35.902 sec)\n",
            "I0527 17:38:05.487065 140028679079808 basic_session_run_hooks.py:260] loss = 2.2154157, step = 81900 (35.902 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.73506\n",
            "I0527 17:38:42.047880 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.73506\n",
            "INFO:tensorflow:loss = 2.7470038, step = 82000 (36.601 sec)\n",
            "I0527 17:38:42.088165 140028679079808 basic_session_run_hooks.py:260] loss = 2.7470038, step = 82000 (36.601 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.80932\n",
            "I0527 17:39:17.643632 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.80932\n",
            "INFO:tensorflow:loss = 2.417312, step = 82100 (35.560 sec)\n",
            "I0527 17:39:17.648102 140028679079808 basic_session_run_hooks.py:260] loss = 2.417312, step = 82100 (35.560 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.93483\n",
            "I0527 17:39:51.717090 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.93483\n",
            "INFO:tensorflow:loss = 2.272299, step = 82200 (34.070 sec)\n",
            "I0527 17:39:51.718432 140028679079808 basic_session_run_hooks.py:260] loss = 2.272299, step = 82200 (34.070 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.8799\n",
            "I0527 17:40:26.440647 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.8799\n",
            "INFO:tensorflow:loss = 2.1340714, step = 82300 (34.724 sec)\n",
            "I0527 17:40:26.442675 140028679079808 basic_session_run_hooks.py:260] loss = 2.1340714, step = 82300 (34.724 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.84071\n",
            "I0527 17:41:01.643075 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.84071\n",
            "INFO:tensorflow:loss = 1.9942625, step = 82400 (35.219 sec)\n",
            "I0527 17:41:01.661338 140028679079808 basic_session_run_hooks.py:260] loss = 1.9942625, step = 82400 (35.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.7749\n",
            "I0527 17:41:37.680234 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.7749\n",
            "INFO:tensorflow:loss = 2.2656164, step = 82500 (36.023 sec)\n",
            "I0527 17:41:37.684048 140028679079808 basic_session_run_hooks.py:260] loss = 2.2656164, step = 82500 (36.023 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.84178\n",
            "I0527 17:42:12.869471 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.84178\n",
            "INFO:tensorflow:loss = 2.5995297, step = 82600 (35.187 sec)\n",
            "I0527 17:42:12.871130 140028679079808 basic_session_run_hooks.py:260] loss = 2.5995297, step = 82600 (35.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.89271\n",
            "I0527 17:42:47.439114 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.89271\n",
            "INFO:tensorflow:loss = 2.348269, step = 82700 (34.570 sec)\n",
            "I0527 17:42:47.440679 140028679079808 basic_session_run_hooks.py:260] loss = 2.348269, step = 82700 (34.570 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.85037\n",
            "I0527 17:43:22.522291 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.85037\n",
            "INFO:tensorflow:loss = 1.5659964, step = 82800 (35.087 sec)\n",
            "I0527 17:43:22.527704 140028679079808 basic_session_run_hooks.py:260] loss = 1.5659964, step = 82800 (35.087 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 82901 into /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt.\n",
            "I0527 17:43:58.031136 140028679079808 basic_session_run_hooks.py:606] Saving checkpoints for 82901 into /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0527 17:44:00.104377 140028679079808 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 2.66075\n",
            "I0527 17:44:00.105497 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.66075\n",
            "INFO:tensorflow:loss = 1.8223449, step = 82900 (37.579 sec)\n",
            "I0527 17:44:00.106470 140028679079808 basic_session_run_hooks.py:260] loss = 1.8223449, step = 82900 (37.579 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.89446\n",
            "I0527 17:44:34.654352 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.89446\n",
            "INFO:tensorflow:loss = 2.0643845, step = 83000 (34.550 sec)\n",
            "I0527 17:44:34.656876 140028679079808 basic_session_run_hooks.py:260] loss = 2.0643845, step = 83000 (34.550 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xByykvJn2u75",
        "colab_type": "text"
      },
      "source": [
        "### Check output directory after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab_type": "code",
        "outputId": "7a60be41-8cad-4db2-9fbe-7d119eb92391",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls {modelDir}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1590424719.29eab163d8d4\n",
            "events.out.tfevents.1590474998.24980bca4a60\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-75846.data-00000-of-00001\n",
            "model.ckpt-75846.index\n",
            "model.ckpt-75846.meta\n",
            "model.ckpt-77141.data-00000-of-00001\n",
            "model.ckpt-77141.index\n",
            "model.ckpt-77141.meta\n",
            "model.ckpt-78364.data-00000-of-00001\n",
            "model.ckpt-78364.index\n",
            "model.ckpt-78364.meta\n",
            "model.ckpt-79808.data-00000-of-00001\n",
            "model.ckpt-79808.index\n",
            "model.ckpt-79808.meta\n",
            "model.ckpt-80000.data-00000-of-00001\n",
            "model.ckpt-80000.index\n",
            "model.ckpt-80000.meta\n",
            "pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U4PkjSQ3AIo",
        "colab_type": "text"
      },
      "source": [
        "## 9. Export model\n",
        ">Save the model to Drive as a `zip` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MDLIkHA3B3W",
        "colab_type": "code",
        "outputId": "d6f770b5-3fca-491d-a1f6-31dee6720452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.chdir(localPath)\n",
        "# Location where the exported model will be saved\n",
        "exportName = selectedModel + '_trained_at_' + '2020-05-26_adam_00004_const_lr_80k'\n",
        "print(exportName)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVxZpU3NOIIj",
        "colab_type": "text"
      },
      "source": [
        "### Optional: Zip all the training files to continue training later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbneB8AnhyOd",
        "colab_type": "code",
        "outputId": "f6ed97d0-3c35-4e60-f7b3-cbfdea14a423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "exportToDrivePath = modelsPath + '/' + exportName\n",
        "outputTrainingFileName = localPath + '/' + exportName + '_training'\n",
        "os.makedirs(localPath + '/' + 'full_training')\n",
        "shutil.copytree(localPath + '/training', localPath + '/' + 'full_training' + '/' + exportName + '_training/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/full_training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM_rHTHsMY2o",
        "colab_type": "code",
        "outputId": "006cc937-c5a0-48ea-8a1f-d44ce5ac270c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#ignore the error if zip creation is successful\n",
        "shutil.make_archive(outputTrainingFileName, 'zip', localPath + '/' + 'full_training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6srhQozOuVm",
        "colab_type": "code",
        "outputId": "48830a13-9584-4f7d-a0e0-761914339bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "shutil.move(outputTrainingFileName + '.zip', modelsPath)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Machine Learning/License plate detection/saved/models/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90WGDg-5GYSF",
        "colab_type": "text"
      },
      "source": [
        "### Optional: convert and save only the model to the local root folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "colab_type": "code",
        "outputId": "d884e562-16da-450c-a9e1-3a01119a06ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "output_directory = '/content/fine_tuned_model/' + exportName\n",
        "\n",
        "lst = os.listdir(modelDir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(modelDir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipelineFilePath} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_training/model.ckpt-80000\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0526 15:20:31.969357 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:419: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0526 15:20:31.975577 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:419: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:138: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0526 15:20:31.975972 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:138: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:3030: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0526 15:20:32.005037 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:3030: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:608: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0526 15:20:32.028939 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:608: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0526 15:20:32.031293 140168632760192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0526 15:20:33.784585 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:157: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0526 15:20:33.794148 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:157: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0526 15:20:33.794327 140168632760192 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0526 15:20:33.870113 140168632760192 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0526 15:20:33.944451 140168632760192 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0526 15:20:34.121495 140168632760192 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0526 15:20:34.197347 140168632760192 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0526 15:20:34.275510 140168632760192 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:1106: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0526 15:20:34.502590 140168632760192 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:1106: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:295: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0526 15:20:34.690215 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:295: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:400: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0526 15:20:34.690463 140168632760192 deprecation.py:323] From /content/models/research/object_detection/exporter.py:400: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:432: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0526 15:20:34.693413 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:432: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:555: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0526 15:20:34.693578 140168632760192 deprecation.py:323] From /content/models/research/object_detection/exporter.py:555: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0526 15:20:34.694457 140168632760192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "206 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/935.56k params)\n",
            "  BoxPredictor_0 (--/12.12k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/3.47k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x288x12, 3.46k/3.46k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor_depthwise (--/2.59k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x288x1, 2.59k/2.59k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/3.47k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x288x12, 3.46k/3.46k params)\n",
            "    BoxPredictor_0/ClassPredictor_depthwise (--/2.59k params)\n",
            "      BoxPredictor_0/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_0/ClassPredictor_depthwise/depthwise_weights (3x3x288x1, 2.59k/2.59k params)\n",
            "  BoxPredictor_1 (--/19.06k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/6.94k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x288x24, 6.91k/6.91k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor_depthwise (--/2.59k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x288x1, 2.59k/2.59k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/6.94k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x288x24, 6.91k/6.91k params)\n",
            "    BoxPredictor_1/ClassPredictor_depthwise (--/2.59k params)\n",
            "      BoxPredictor_1/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_1/ClassPredictor_depthwise/depthwise_weights (3x3x288x1, 2.59k/2.59k params)\n",
            "  BoxPredictor_2 (--/33.84k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor_depthwise (--/4.61k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor_depthwise (--/4.61k params)\n",
            "      BoxPredictor_2/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_2/ClassPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "  BoxPredictor_3 (--/16.94k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_3/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_3/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "  BoxPredictor_4 (--/16.94k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_4/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_4/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "  BoxPredictor_5 (--/8.50k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor_depthwise (--/1.15k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor_depthwise (--/1.15k params)\n",
            "      BoxPredictor_5/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_5/ClassPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "  FeatureExtractor (--/828.16k params)\n",
            "    FeatureExtractor/MobilenetV3 (--/828.16k params)\n",
            "      FeatureExtractor/MobilenetV3/Conv (--/432 params)\n",
            "        FeatureExtractor/MobilenetV3/Conv/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/Conv/weights (3x3x3x16, 432/432 params)\n",
            "      FeatureExtractor/MobilenetV3/Conv_1 (--/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/Conv_1/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/Conv_1/weights (1x1x48x288, 13.82k/13.82k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv (--/680 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv/depthwise (--/144 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/depthwise/depthwise_weights (3x3x16x1, 144/144 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv/project (--/256 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/project/weights (1x1x16x16, 256/256 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite (--/280 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv (--/136 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv/biases (8, 8/8 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv/weights (1x1x16x8, 128/128 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv_1 (--/144 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/biases (16, 16/16 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/weights (1x1x8x16, 128/128 params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_1 (--/3.53k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise (--/648 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise/depthwise_weights (3x3x72x1, 648/648 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_1/expand (--/1.15k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/expand/weights (1x1x16x72, 1.15k/1.15k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_1/project (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/project/weights (1x1x72x24, 1.73k/1.73k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_10 (--/76.68k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise (--/7.20k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise/depthwise_weights (5x5x288x1, 7.20k/7.20k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/expand (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/expand/weights (1x1x48x288, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/project (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/project/weights (1x1x288x48, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite (--/41.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv (--/20.81k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv/biases (72, 72/72 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv/weights (1x1x288x72, 20.74k/20.74k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1 (--/21.02k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/biases (288, 288/288 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/weights (1x1x72x288, 20.74k/20.74k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_2 (--/5.02k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise (--/792 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise/depthwise_weights (3x3x88x1, 792/792 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_2/expand (--/2.11k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/expand/weights (1x1x24x88, 2.11k/2.11k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_2/project (--/2.11k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/project/weights (1x1x88x24, 2.11k/2.11k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_3 (--/13.27k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise (--/2.40k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise/depthwise_weights (5x5x96x1, 2.40k/2.40k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/expand (--/2.30k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/expand/weights (1x1x24x96, 2.30k/2.30k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/project (--/3.84k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/project/weights (1x1x96x40, 3.84k/3.84k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite (--/4.73k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv (--/2.33k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv/biases (24, 24/24 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv/weights (1x1x96x24, 2.30k/2.30k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1 (--/2.40k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/biases (96, 96/96 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/weights (1x1x24x96, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_4 (--/56.22k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise (--/6.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise/depthwise_weights (5x5x240x1, 6.00k/6.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/expand (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/expand/weights (1x1x40x240, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/project (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/project/weights (1x1x240x40, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite (--/31.02k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv (--/15.42k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv/biases (64, 64/64 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv/weights (1x1x240x64, 15.36k/15.36k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1 (--/15.60k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/biases (240, 240/240 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/weights (1x1x64x240, 15.36k/15.36k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_5 (--/56.22k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise (--/6.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise/depthwise_weights (5x5x240x1, 6.00k/6.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/expand (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/expand/weights (1x1x40x240, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/project (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/project/weights (1x1x240x40, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite (--/31.02k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv (--/15.42k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv/biases (64, 64/64 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv/weights (1x1x240x64, 15.36k/15.36k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1 (--/15.60k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/biases (240, 240/240 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/weights (1x1x64x240, 15.36k/15.36k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_6 (--/21.39k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise (--/3.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise/depthwise_weights (5x5x120x1, 3.00k/3.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/expand (--/4.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/expand/weights (1x1x40x120, 4.80k/4.80k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/project (--/5.76k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/project/weights (1x1x120x48, 5.76k/5.76k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite (--/7.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv (--/3.87k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv/biases (32, 32/32 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv/weights (1x1x120x32, 3.84k/3.84k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1 (--/3.96k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1/biases (120, 120/120 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1/weights (1x1x32x120, 3.84k/3.84k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_7 (--/29.13k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise (--/3.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise/depthwise_weights (5x5x144x1, 3.60k/3.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/expand (--/6.91k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/expand/weights (1x1x48x144, 6.91k/6.91k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/project (--/6.91k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/project/weights (1x1x144x48, 6.91k/6.91k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite (--/11.70k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv (--/5.80k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv/biases (40, 40/40 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv/weights (1x1x144x40, 5.76k/5.76k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1 (--/5.90k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1/biases (144, 144/144 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1/weights (1x1x40x144, 5.76k/5.76k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_8 (--/76.68k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise (--/7.20k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise/depthwise_weights (5x5x288x1, 7.20k/7.20k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/expand (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/expand/weights (1x1x48x288, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/project (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/project/weights (1x1x288x48, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite (--/41.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv (--/20.81k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv/biases (72, 72/72 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv/weights (1x1x288x72, 20.74k/20.74k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1 (--/21.02k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1/biases (288, 288/288 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1/weights (1x1x72x288, 20.74k/20.74k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_9 (--/76.68k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise (--/7.20k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise/depthwise_weights (5x5x288x1, 7.20k/7.20k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/expand (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/expand/weights (1x1x48x288, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/project (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/project/weights (1x1x288x48, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite (--/41.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv (--/20.81k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv/biases (72, 72/72 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv/weights (1x1x288x72, 20.74k/20.74k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1 (--/21.02k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1/biases (288, 288/288 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1/weights (1x1x72x288, 20.74k/20.74k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_2_1x1_256 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_2_1x1_256/weights (1x1x288x256, 73.73k/73.73k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512 (--/131.07k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128 (--/8.19k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128/weights (1x1x64x128, 8.19k/8.19k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128_depthwise (--/576 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
            "\n",
            "======================End of Report==========================\n",
            "206 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/21.69k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.40k/2.40k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.40k/2.40k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.40k/2.40k flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_2 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_2 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_1 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_3 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_3 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_3 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_2 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/GreaterEqual (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_2 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_1 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_1 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/sub_1 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/sub (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/mul (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_3 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Sum (299/299 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less_1 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less_2 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_2 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_1 (100/100 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (20/20 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (20/20 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:449: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0526 15:20:35.648171 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:449: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:359: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0526 15:20:36.438353 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:359: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-05-26 15:20:36.439712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-26 15:20:36.453379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.453916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-26 15:20:36.454213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 15:20:36.456549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-26 15:20:36.458475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-26 15:20:36.458849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-26 15:20:36.466037: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-26 15:20:36.467069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-26 15:20:36.474922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-26 15:20:36.475076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.475727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.476346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-26 15:20:36.484814: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-05-26 15:20:36.485103: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2290bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-26 15:20:36.485139: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-26 15:20:36.573440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.574127: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2290d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-26 15:20:36.574160: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-05-26 15:20:36.574317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.574886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-26 15:20:36.574950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 15:20:36.574992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-26 15:20:36.575008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-26 15:20:36.575022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-26 15:20:36.575039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-26 15:20:36.575052: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-26 15:20:36.575066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-26 15:20:36.575124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.575625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.576139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-26 15:20:36.576203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 15:20:36.577332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-26 15:20:36.577354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-26 15:20:36.577360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-26 15:20:36.577451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.577989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.578484: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-26 15:20:36.578519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_training/model.ckpt-80000\n",
            "I0526 15:20:36.580316 140168632760192 saver.py:1284] Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_training/model.ckpt-80000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0526 15:20:38.076395 140168632760192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-05-26 15:20:38.548755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:38.549362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-26 15:20:38.549452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 15:20:38.549479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-26 15:20:38.549501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-26 15:20:38.549523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-26 15:20:38.549563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-26 15:20:38.549605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-26 15:20:38.549629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-26 15:20:38.549745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:38.550437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:38.551005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-26 15:20:38.551045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-26 15:20:38.551072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-26 15:20:38.551082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-26 15:20:38.551189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:38.551766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:38.552389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_training/model.ckpt-80000\n",
            "I0526 15:20:38.553462 140168632760192 saver.py:1284] Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_training/model.ckpt-80000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0526 15:20:39.137994 140168632760192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0526 15:20:39.138255 140168632760192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 350 variables.\n",
            "I0526 15:20:39.501126 140168632760192 graph_util_impl.py:334] Froze 350 variables.\n",
            "INFO:tensorflow:Converted 350 variables to const ops.\n",
            "I0526 15:20:39.554823 140168632760192 graph_util_impl.py:394] Converted 350 variables to const ops.\n",
            "2020-05-26 15:20:39.648335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:39.648927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-26 15:20:39.649031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 15:20:39.649060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-26 15:20:39.649077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-26 15:20:39.649105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-26 15:20:39.649127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-26 15:20:39.649147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-26 15:20:39.649164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-26 15:20:39.649240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:39.649838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:39.650392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-26 15:20:39.650433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-26 15:20:39.650463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-26 15:20:39.650470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-26 15:20:39.650553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:39.651109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:39.651584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0526 15:20:40.106542 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:326: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0526 15:20:40.106987 140168632760192 deprecation.py:323] From /content/models/research/object_detection/exporter.py:326: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:332: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W0526 15:20:40.107371 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:332: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:335: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W0526 15:20:40.107511 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:335: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:340: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W0526 15:20:40.107669 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:340: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:342: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "W0526 15:20:40.107761 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:342: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0526 15:20:40.107997 140168632760192 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0526 15:20:40.108076 140168632760192 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/fine_tuned_model/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k/saved_model/saved_model.pb\n",
            "I0526 15:20:40.299122 140168632760192 builder_impl.py:425] SavedModel written to: /content/fine_tuned_model/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k/saved_model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:223: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0526 15:20:40.317552 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:223: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to /content/fine_tuned_model/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k/pipeline.config\n",
            "I0526 15:20:40.317744 140168632760192 config_util.py:225] Writing pipeline config file to /content/fine_tuned_model/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09AOThWkaQv",
        "colab_type": "text"
      },
      "source": [
        "#### Zip the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDbg8IlZkOP7",
        "colab_type": "code",
        "outputId": "849c033a-82f5-4c37-b2fa-a6bbcb3c10a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "exportToDrivePath = modelsPath + '/' + exportName\n",
        "outputFileName = localPath + '/' + exportName\n",
        "\n",
        "#ignore the error if zip creation is successful\n",
        "shutil.make_archive(outputFileName, 'zip', localPath + '/fine_tuned_model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhS49yAiGqW3",
        "colab_type": "text"
      },
      "source": [
        "#### Move the `zip`ped file to the Drive folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsOMNVqikOqX",
        "colab_type": "code",
        "outputId": "1a57ebc1-913b-4254-cc0f-ed294d9c19dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "shutil.move(outputFileName + '.zip', modelsPath)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Machine Learning/License plate detection/saved/models/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEdkQ5pQ1xtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}