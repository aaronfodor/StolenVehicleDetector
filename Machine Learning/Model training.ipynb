{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yhzxsJb3dpWq",
        "iCNYAaC7w6N8",
        "Fs-6YZo3x5vO"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQCnYPVDrsgx"
      },
      "source": [
        "# Model training notebook\n",
        ">This notebook uses Tensorflow Object Detection API to train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq"
      },
      "source": [
        "## 1. Prepare the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Caw1Z0HYFKii",
        "outputId": "e3e18f40-031d-4be4-d66f-4c50a61d095b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Clone the tensorflow models repository\n",
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ITKw4MwFKqd",
        "outputId": "599f6b13-5dcd-4f15-c0fa-81e0a0d43858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash\n",
        "sudo apt install -y protobuf-compiler\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "Processing /content/models/research\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.10.0)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.24.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: tf-models-official in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.3.0)\n",
            "Requirement already satisfied: fastavro<0.24,>=0.21.4 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.23.6)\n",
            "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n",
            "Requirement already satisfied: pyarrow<0.18.0,>=0.15.1; python_version >= \"3.0\" or platform_system != \"Windows\" in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.24.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: oauth2client<4,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: future<1.0.0,>=0.18.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.18.2)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.11.0)\n",
            "Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.5.8)\n",
            "Requirement already satisfied: numpy<2,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.18.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (50.3.0)\n",
            "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.1.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.4.0.44)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.1.91)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.7.12)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (3.13)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.8)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock<3.0.0,>=1.0.1->apache-beam->object-detection==0.1) (5.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam->object-detection==0.1) (4.6)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.35.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (20.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.24.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->tf-models-official->object-detection==0.1) (0.1.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (0.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.52.0)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.2.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1579568 sha256=4f21fdbae63b468e80f1c983c1320c915ee153507ade6f2ed7389b013dad4d89\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6gcwgykc/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4JmhUvlJJcc",
        "outputId": "4b70213b-ba53-4461-f512-4f3ddbf90942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Test the installation.\n",
        "%%bash\n",
        "cd models/research/\n",
        "python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-04 19:44:59.335075: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "2020-10-04 19:45:01.468040: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-04 19:45:01.512857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-04 19:45:01.513422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2020-10-04 19:45:01.513469: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-04 19:45:01.782973: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-04 19:45:01.912811: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-04 19:45:01.942520: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-04 19:45:02.213615: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-04 19:45:02.243329: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-04 19:45:02.765121: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-04 19:45:02.765326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-04 19:45:02.766057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-04 19:45:02.766666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-04 19:45:02.835180: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-10-04 19:45:02.835494: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1841480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-04 19:45:02.835530: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-04 19:45:02.960937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-04 19:45:02.961751: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1841640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-04 19:45:02.961787: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-10-04 19:45:02.963031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-04 19:45:02.963647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2020-10-04 19:45:02.963699: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-04 19:45:02.963757: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-04 19:45:02.963785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-04 19:45:02.963810: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-04 19:45:02.963836: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-04 19:45:02.963858: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-04 19:45:02.963879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-04 19:45:02.963983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-04 19:45:02.964662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-04 19:45:02.965230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-04 19:45:02.968929: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-04 19:45:06.993935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-04 19:45:06.993989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-10-04 19:45:06.993998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-10-04 19:45:06.998036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-04 19:45:06.998697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-04 19:45:06.999220: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-04 19:45:06.999256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14968 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 9.95s\n",
            "I1004 19:45:11.206765 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 9.95s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1004 19:45:11.207973 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I1004 19:45:11.240918 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I1004 19:45:11.260904 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I1004 19:45:11.281920 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
            "I1004 19:45:11.418412 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "I1004 19:45:11.553133 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "I1004 19:45:11.690238 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "I1004 19:45:11.826202 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "I1004 19:45:11.969646 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I1004 19:45:12.010515 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1004 19:45:12.280736 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1004 19:45:12.280875 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n",
            "I1004 19:45:12.280978 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n",
            "I1004 19:45:12.286717 140060670326656 efficientnet_model.py:148] round_filter input=32 output=32\n",
            "I1004 19:45:12.309577 140060670326656 efficientnet_model.py:148] round_filter input=32 output=32\n",
            "I1004 19:45:12.309682 140060670326656 efficientnet_model.py:148] round_filter input=16 output=16\n",
            "I1004 19:45:12.378352 140060670326656 efficientnet_model.py:148] round_filter input=16 output=16\n",
            "I1004 19:45:12.378490 140060670326656 efficientnet_model.py:148] round_filter input=24 output=24\n",
            "I1004 19:45:12.559829 140060670326656 efficientnet_model.py:148] round_filter input=24 output=24\n",
            "I1004 19:45:12.559949 140060670326656 efficientnet_model.py:148] round_filter input=40 output=40\n",
            "I1004 19:45:12.743647 140060670326656 efficientnet_model.py:148] round_filter input=40 output=40\n",
            "I1004 19:45:12.743766 140060670326656 efficientnet_model.py:148] round_filter input=80 output=80\n",
            "I1004 19:45:13.025088 140060670326656 efficientnet_model.py:148] round_filter input=80 output=80\n",
            "I1004 19:45:13.025243 140060670326656 efficientnet_model.py:148] round_filter input=112 output=112\n",
            "I1004 19:45:13.307159 140060670326656 efficientnet_model.py:148] round_filter input=112 output=112\n",
            "I1004 19:45:13.307316 140060670326656 efficientnet_model.py:148] round_filter input=192 output=192\n",
            "I1004 19:45:13.802947 140060670326656 efficientnet_model.py:148] round_filter input=192 output=192\n",
            "I1004 19:45:13.803103 140060670326656 efficientnet_model.py:148] round_filter input=320 output=320\n",
            "I1004 19:45:13.887025 140060670326656 efficientnet_model.py:148] round_filter input=1280 output=1280\n",
            "I1004 19:45:13.925720 140060670326656 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1004 19:45:14.003025 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1004 19:45:14.003146 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 88\n",
            "I1004 19:45:14.003194 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 4\n",
            "I1004 19:45:14.008129 140060670326656 efficientnet_model.py:148] round_filter input=32 output=32\n",
            "I1004 19:45:14.029379 140060670326656 efficientnet_model.py:148] round_filter input=32 output=32\n",
            "I1004 19:45:14.029488 140060670326656 efficientnet_model.py:148] round_filter input=16 output=16\n",
            "I1004 19:45:14.171010 140060670326656 efficientnet_model.py:148] round_filter input=16 output=16\n",
            "I1004 19:45:14.171121 140060670326656 efficientnet_model.py:148] round_filter input=24 output=24\n",
            "I1004 19:45:14.448020 140060670326656 efficientnet_model.py:148] round_filter input=24 output=24\n",
            "I1004 19:45:14.448166 140060670326656 efficientnet_model.py:148] round_filter input=40 output=40\n",
            "I1004 19:45:14.723063 140060670326656 efficientnet_model.py:148] round_filter input=40 output=40\n",
            "I1004 19:45:14.723195 140060670326656 efficientnet_model.py:148] round_filter input=80 output=80\n",
            "I1004 19:45:15.098052 140060670326656 efficientnet_model.py:148] round_filter input=80 output=80\n",
            "I1004 19:45:15.098194 140060670326656 efficientnet_model.py:148] round_filter input=112 output=112\n",
            "I1004 19:45:15.472212 140060670326656 efficientnet_model.py:148] round_filter input=112 output=112\n",
            "I1004 19:45:15.472361 140060670326656 efficientnet_model.py:148] round_filter input=192 output=192\n",
            "I1004 19:45:15.942492 140060670326656 efficientnet_model.py:148] round_filter input=192 output=192\n",
            "I1004 19:45:15.942642 140060670326656 efficientnet_model.py:148] round_filter input=320 output=320\n",
            "I1004 19:45:16.133354 140060670326656 efficientnet_model.py:148] round_filter input=1280 output=1280\n",
            "I1004 19:45:16.168463 140060670326656 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1004 19:45:16.254392 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1004 19:45:16.254523 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 112\n",
            "I1004 19:45:16.254575 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 5\n",
            "I1004 19:45:16.259536 140060670326656 efficientnet_model.py:148] round_filter input=32 output=32\n",
            "I1004 19:45:16.280063 140060670326656 efficientnet_model.py:148] round_filter input=32 output=32\n",
            "I1004 19:45:16.280160 140060670326656 efficientnet_model.py:148] round_filter input=16 output=16\n",
            "I1004 19:45:16.577311 140060670326656 efficientnet_model.py:148] round_filter input=16 output=16\n",
            "I1004 19:45:16.577501 140060670326656 efficientnet_model.py:148] round_filter input=24 output=24\n",
            "I1004 19:45:16.852041 140060670326656 efficientnet_model.py:148] round_filter input=24 output=24\n",
            "I1004 19:45:16.852185 140060670326656 efficientnet_model.py:148] round_filter input=40 output=48\n",
            "I1004 19:45:17.129841 140060670326656 efficientnet_model.py:148] round_filter input=40 output=48\n",
            "I1004 19:45:17.129995 140060670326656 efficientnet_model.py:148] round_filter input=80 output=88\n",
            "I1004 19:45:17.503363 140060670326656 efficientnet_model.py:148] round_filter input=80 output=88\n",
            "I1004 19:45:17.503526 140060670326656 efficientnet_model.py:148] round_filter input=112 output=120\n",
            "I1004 19:45:17.878235 140060670326656 efficientnet_model.py:148] round_filter input=112 output=120\n",
            "I1004 19:45:17.878396 140060670326656 efficientnet_model.py:148] round_filter input=192 output=208\n",
            "I1004 19:45:18.356127 140060670326656 efficientnet_model.py:148] round_filter input=192 output=208\n",
            "I1004 19:45:18.356276 140060670326656 efficientnet_model.py:148] round_filter input=320 output=352\n",
            "I1004 19:45:18.536190 140060670326656 efficientnet_model.py:148] round_filter input=1280 output=1408\n",
            "I1004 19:45:18.572615 140060670326656 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1004 19:45:18.661453 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1004 19:45:18.661588 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 160\n",
            "I1004 19:45:18.661671 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 6\n",
            "I1004 19:45:18.666676 140060670326656 efficientnet_model.py:148] round_filter input=32 output=40\n",
            "I1004 19:45:18.688597 140060670326656 efficientnet_model.py:148] round_filter input=32 output=40\n",
            "I1004 19:45:18.688715 140060670326656 efficientnet_model.py:148] round_filter input=16 output=24\n",
            "I1004 19:45:18.827024 140060670326656 efficientnet_model.py:148] round_filter input=16 output=24\n",
            "I1004 19:45:18.827136 140060670326656 efficientnet_model.py:148] round_filter input=24 output=32\n",
            "I1004 19:45:19.109315 140060670326656 efficientnet_model.py:148] round_filter input=24 output=32\n",
            "I1004 19:45:19.109473 140060670326656 efficientnet_model.py:148] round_filter input=40 output=48\n",
            "I1004 19:45:19.397605 140060670326656 efficientnet_model.py:148] round_filter input=40 output=48\n",
            "I1004 19:45:19.397745 140060670326656 efficientnet_model.py:148] round_filter input=80 output=96\n",
            "I1004 19:45:19.878149 140060670326656 efficientnet_model.py:148] round_filter input=80 output=96\n",
            "I1004 19:45:19.878306 140060670326656 efficientnet_model.py:148] round_filter input=112 output=136\n",
            "I1004 19:45:20.550794 140060670326656 efficientnet_model.py:148] round_filter input=112 output=136\n",
            "I1004 19:45:20.550945 140060670326656 efficientnet_model.py:148] round_filter input=192 output=232\n",
            "I1004 19:45:21.119870 140060670326656 efficientnet_model.py:148] round_filter input=192 output=232\n",
            "I1004 19:45:21.120023 140060670326656 efficientnet_model.py:148] round_filter input=320 output=384\n",
            "I1004 19:45:21.299649 140060670326656 efficientnet_model.py:148] round_filter input=1280 output=1536\n",
            "I1004 19:45:21.334136 140060670326656 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1004 19:45:21.427559 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1004 19:45:21.427680 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 224\n",
            "I1004 19:45:21.427731 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n",
            "I1004 19:45:21.432747 140060670326656 efficientnet_model.py:148] round_filter input=32 output=48\n",
            "I1004 19:45:21.453889 140060670326656 efficientnet_model.py:148] round_filter input=32 output=48\n",
            "I1004 19:45:21.453987 140060670326656 efficientnet_model.py:148] round_filter input=16 output=24\n",
            "I1004 19:45:21.591966 140060670326656 efficientnet_model.py:148] round_filter input=16 output=24\n",
            "I1004 19:45:21.592072 140060670326656 efficientnet_model.py:148] round_filter input=24 output=32\n",
            "I1004 19:45:21.961718 140060670326656 efficientnet_model.py:148] round_filter input=24 output=32\n",
            "I1004 19:45:21.961899 140060670326656 efficientnet_model.py:148] round_filter input=40 output=56\n",
            "I1004 19:45:22.344681 140060670326656 efficientnet_model.py:148] round_filter input=40 output=56\n",
            "I1004 19:45:22.344827 140060670326656 efficientnet_model.py:148] round_filter input=80 output=112\n",
            "I1004 19:45:22.909036 140060670326656 efficientnet_model.py:148] round_filter input=80 output=112\n",
            "I1004 19:45:22.909183 140060670326656 efficientnet_model.py:148] round_filter input=112 output=160\n",
            "I1004 19:45:23.487071 140060670326656 efficientnet_model.py:148] round_filter input=112 output=160\n",
            "I1004 19:45:23.487227 140060670326656 efficientnet_model.py:148] round_filter input=192 output=272\n",
            "I1004 19:45:24.249208 140060670326656 efficientnet_model.py:148] round_filter input=192 output=272\n",
            "I1004 19:45:24.249361 140060670326656 efficientnet_model.py:148] round_filter input=320 output=448\n",
            "I1004 19:45:24.428097 140060670326656 efficientnet_model.py:148] round_filter input=1280 output=1792\n",
            "I1004 19:45:24.462892 140060670326656 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1004 19:45:24.567624 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1004 19:45:24.567745 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 288\n",
            "I1004 19:45:24.567797 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n",
            "I1004 19:45:24.572685 140060670326656 efficientnet_model.py:148] round_filter input=32 output=48\n",
            "I1004 19:45:24.593488 140060670326656 efficientnet_model.py:148] round_filter input=32 output=48\n",
            "I1004 19:45:24.593580 140060670326656 efficientnet_model.py:148] round_filter input=16 output=24\n",
            "I1004 19:45:25.040062 140060670326656 efficientnet_model.py:148] round_filter input=16 output=24\n",
            "I1004 19:45:25.040215 140060670326656 efficientnet_model.py:148] round_filter input=24 output=40\n",
            "I1004 19:45:25.513758 140060670326656 efficientnet_model.py:148] round_filter input=24 output=40\n",
            "I1004 19:45:25.513910 140060670326656 efficientnet_model.py:148] round_filter input=40 output=64\n",
            "I1004 19:45:25.992465 140060670326656 efficientnet_model.py:148] round_filter input=40 output=64\n",
            "I1004 19:45:25.992634 140060670326656 efficientnet_model.py:148] round_filter input=80 output=128\n",
            "I1004 19:45:26.679023 140060670326656 efficientnet_model.py:148] round_filter input=80 output=128\n",
            "I1004 19:45:26.679171 140060670326656 efficientnet_model.py:148] round_filter input=112 output=176\n",
            "I1004 19:45:27.346664 140060670326656 efficientnet_model.py:148] round_filter input=112 output=176\n",
            "I1004 19:45:27.346814 140060670326656 efficientnet_model.py:148] round_filter input=192 output=304\n",
            "I1004 19:45:28.209563 140060670326656 efficientnet_model.py:148] round_filter input=192 output=304\n",
            "I1004 19:45:28.209705 140060670326656 efficientnet_model.py:148] round_filter input=320 output=512\n",
            "I1004 19:45:28.487475 140060670326656 efficientnet_model.py:148] round_filter input=1280 output=2048\n",
            "I1004 19:45:28.522057 140060670326656 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1004 19:45:28.641786 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1004 19:45:28.641906 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n",
            "I1004 19:45:28.641981 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n",
            "I1004 19:45:28.647622 140060670326656 efficientnet_model.py:148] round_filter input=32 output=56\n",
            "I1004 19:45:28.670546 140060670326656 efficientnet_model.py:148] round_filter input=32 output=56\n",
            "I1004 19:45:28.670643 140060670326656 efficientnet_model.py:148] round_filter input=16 output=32\n",
            "I1004 19:45:28.883882 140060670326656 efficientnet_model.py:148] round_filter input=16 output=32\n",
            "I1004 19:45:28.883999 140060670326656 efficientnet_model.py:148] round_filter input=24 output=40\n",
            "I1004 19:45:29.453038 140060670326656 efficientnet_model.py:148] round_filter input=24 output=40\n",
            "I1004 19:45:29.453199 140060670326656 efficientnet_model.py:148] round_filter input=40 output=72\n",
            "I1004 19:45:30.031011 140060670326656 efficientnet_model.py:148] round_filter input=40 output=72\n",
            "I1004 19:45:30.031162 140060670326656 efficientnet_model.py:148] round_filter input=80 output=144\n",
            "I1004 19:45:31.098636 140060670326656 efficientnet_model.py:148] round_filter input=80 output=144\n",
            "I1004 19:45:31.098784 140060670326656 efficientnet_model.py:148] round_filter input=112 output=200\n",
            "I1004 19:45:31.866714 140060670326656 efficientnet_model.py:148] round_filter input=112 output=200\n",
            "I1004 19:45:31.866880 140060670326656 efficientnet_model.py:148] round_filter input=192 output=344\n",
            "I1004 19:45:32.929254 140060670326656 efficientnet_model.py:148] round_filter input=192 output=344\n",
            "I1004 19:45:32.929418 140060670326656 efficientnet_model.py:148] round_filter input=320 output=576\n",
            "I1004 19:45:33.218733 140060670326656 efficientnet_model.py:148] round_filter input=1280 output=2304\n",
            "I1004 19:45:33.256222 140060670326656 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1004 19:45:33.392994 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1004 19:45:33.393125 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n",
            "I1004 19:45:33.393174 140060670326656 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n",
            "I1004 19:45:33.398161 140060670326656 efficientnet_model.py:148] round_filter input=32 output=64\n",
            "I1004 19:45:33.420267 140060670326656 efficientnet_model.py:148] round_filter input=32 output=64\n",
            "I1004 19:45:33.420383 140060670326656 efficientnet_model.py:148] round_filter input=16 output=32\n",
            "I1004 19:45:33.714507 140060670326656 efficientnet_model.py:148] round_filter input=16 output=32\n",
            "I1004 19:45:33.714650 140060670326656 efficientnet_model.py:148] round_filter input=24 output=48\n",
            "I1004 19:45:34.382073 140060670326656 efficientnet_model.py:148] round_filter input=24 output=48\n",
            "I1004 19:45:34.382224 140060670326656 efficientnet_model.py:148] round_filter input=40 output=80\n",
            "I1004 19:45:35.042603 140060670326656 efficientnet_model.py:148] round_filter input=40 output=80\n",
            "I1004 19:45:35.042751 140060670326656 efficientnet_model.py:148] round_filter input=80 output=160\n",
            "I1004 19:45:35.995796 140060670326656 efficientnet_model.py:148] round_filter input=80 output=160\n",
            "I1004 19:45:35.995965 140060670326656 efficientnet_model.py:148] round_filter input=112 output=224\n",
            "I1004 19:45:36.959812 140060670326656 efficientnet_model.py:148] round_filter input=112 output=224\n",
            "I1004 19:45:36.959963 140060670326656 efficientnet_model.py:148] round_filter input=192 output=384\n",
            "I1004 19:45:38.565533 140060670326656 efficientnet_model.py:148] round_filter input=192 output=384\n",
            "I1004 19:45:38.565684 140060670326656 efficientnet_model.py:148] round_filter input=320 output=640\n",
            "I1004 19:45:38.941678 140060670326656 efficientnet_model.py:148] round_filter input=1280 output=2560\n",
            "I1004 19:45:38.977048 140060670326656 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.12s\n",
            "I1004 19:45:39.130543 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I1004 19:45:39.138282 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1004 19:45:39.140214 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1004 19:45:39.140803 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1004 19:45:39.142265 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1004 19:45:39.143859 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1004 19:45:39.144402 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1004 19:45:39.145471 140060670326656 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 20 tests in 37.893s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwWSNonPvMwj"
      },
      "source": [
        "### Import every dependency used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "outputId": "e85a7efc-1d7d-475f-a97d-d97cef2c5e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import zipfile\n",
        "import shutil\n",
        "import re\n",
        "import numpy as np\n",
        "print(tf.__version__)\n",
        "print(np.__version__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "1.18.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRsB06WbPKsW",
        "outputId": "2344cff9-dd62-47df-c597-910bc50081bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Oct  4 19:48:33 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHXNeWqrwXvd"
      },
      "source": [
        "### Define paths\n",
        "\n",
        ">Paths defined to work remotely on google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGThu1Y2P3Yr"
      },
      "source": [
        "rootPath = '/content/drive/My Drive/Machine Learning/Stolen vehicle detection'\n",
        "dataPath = rootPath + '/data'\n",
        "savedPath = rootPath + '/saved'\n",
        "modelsPath = savedPath + '/models'\n",
        "\n",
        "localPath = '/content'\n",
        "localDataPath = localPath + '/data'\n",
        "modelDir = localPath + '/training'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkvqHD8hwago"
      },
      "source": [
        "### Mount Google Drive to this Notebook instance\n",
        ">As the dataset has been prepared previously and updated to Google Drive, the model building and training process will be done there, not locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaWYrZfzQN0b",
        "outputId": "6bd9a82e-292c-4bc7-bbe9-69ff68067fec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "os.chdir(localPath)\n",
        "# Show current directory\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "\n",
            "Mounted at /content/drive\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz8DYww8vJqv"
      },
      "source": [
        "### Prepare and test Object Detection module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "outputId": "c8949837-08d5-4596-d1f2-36645c6ac8cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content\n",
        "\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!python object_detection/builders/model_builder_test.py\n",
        "\n",
        "%cd /content\n",
        "repo_url = 'https://github.com/Tony607/object_detection_demo'\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144433 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/models/research\n",
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n",
            "/content\n",
            "Cloning into 'object_detection_demo'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Total 124 (delta 0), reused 0 (delta 0), pack-reused 124\u001b[K\n",
            "Receiving objects: 100% (124/124), 11.16 MiB | 29.68 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/object_detection_demo\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKarz_2exv8j"
      },
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcShChmNxxFS"
      },
      "source": [
        "### Choose a pre-trained model\n",
        "\n",
        ">The model used for this project is `ssd_mobilenet_v3_large_coco`.\n",
        "Other models are available [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models).\n",
        ">Real time inference is necessary, so a model with good inference speed (`ms`) needed to be chosen with a relativly high `mAP` on COCO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "067U-tIGlji4"
      },
      "source": [
        "# Number of training steps\n",
        "num_steps = 90000\n",
        "\n",
        "# Number of evaluation steps\n",
        "num_eval_steps = 1000\n",
        "\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05n16DtExXtr"
      },
      "source": [
        "# Models to work with\n",
        "MODELS_CONFIG = {\n",
        "\n",
        "    'ssd_quantized_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_quantized_300x300_coco.config',\n",
        "        'batch_size': 32,\n",
        "    },\n",
        "\n",
        "    'ssdlite_mobilenet_v2': {\n",
        "        'model_name': 'ssdlite_mobilenet_v2_coco_2018_05_09',\n",
        "        'pipeline_file': 'ssdlite_mobilenet_v2_coco.config',\n",
        "        'batch_size': 32,\n",
        "    },\n",
        "\n",
        "    'ssd_mobilenet_v2_oid': {\n",
        "        'model_name': 'ssd_mobilenet_v2_oid_v4_2018_12_12',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_oid_v4.config',\n",
        "        'batch_size': 32,\n",
        "    },\n",
        "\n",
        "    'ssd_mobilenet_v3_small_coco': {\n",
        "        'model_name': 'ssd_mobilenet_v3_small_coco_2019_08_14',\n",
        "        'pipeline_file': 'ssdlite_mobilenet_v3_small_320x320_coco.config',\n",
        "        'batch_size': 32,\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selectedModel = 'ssd_mobilenet_v3_small_coco'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Cy3YIhzTtn"
      },
      "source": [
        "# Name of the object detection model to use\n",
        "MODEL = MODELS_CONFIG[selectedModel]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API\n",
        "pipeline_file = MODELS_CONFIG[selectedModel]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colab's Tesla K80 GPU memory for selected model\n",
        "batch_size = MODELS_CONFIG[selectedModel]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## 3. Optional: download base model\n",
        ">Download the selected model in the MODELS_CONFIG file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL"
      },
      "source": [
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehahEt6Lz_kF"
      },
      "source": [
        "### Check downloaded model content\n",
        ">This is the directory of the \"fine_tune_checkpoint\" that is used in the config file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "outputId": "a447f317-05db-4b29-e115-2573f5479f5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 131M\n",
            "drwxr-x---  3 345018 89939 4.0K Dec 12  2018 .\n",
            "drwxr-xr-x 63 root   root  4.0K May 25 16:32 ..\n",
            "-rw-r-----  1 345018 89939   77 Dec 12  2018 checkpoint\n",
            "-rw-r-----  1 345018 89939  64M Dec 12  2018 frozen_inference_graph.pb\n",
            "-rw-r-----  1 345018 89939  56M Dec 12  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r-----  1 345018 89939  14K Dec 12  2018 model.ckpt.index\n",
            "-rw-r-----  1 345018 89939  12M Dec 12  2018 model.ckpt.meta\n",
            "-rw-r-----  1 345018 89939 4.2K Dec 12  2018 pipeline.config\n",
            "drwxr-x---  3 345018 89939 4.0K Dec 12  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "outputId": "5697acd2-9efb-42b6-8156-aeb7b0162461",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "source": [
        "pipelineFilePath = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "assert os.path.isfile(pipelineFilePath), '`{}` not exist'.format(pipelineFilePath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzPTd8MQlCiq"
      },
      "source": [
        "## 4. Optional: import saved model\n",
        ">If a previously saved model is selected to work with. The `zip` file is placed on Google Drive, but working there would be slow so needs to be extracted locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svL2kLXPlBiM",
        "outputId": "90526390-9604-40bf-eb46-b361abeb377d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Name of the object detection model to load\n",
        "modelToLoad = 'ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training'\n",
        "\n",
        "modelDir = localPath + '/' + 'training'\n",
        "pipelineFilePath = modelDir + '/' + modelToLoad + '/' + 'pipeline.config'\n",
        "\n",
        "os.chdir(localPath)\n",
        "\n",
        "if (os.path.exists(modelDir)):\n",
        "  shutil.rmtree(modelDir)\n",
        "\n",
        "os.mkdir(modelDir)\n",
        "os.chdir(modelDir)\n",
        "\n",
        "# Load the frozen model that is needed for inference\n",
        "# Run it only when the model is not yet extracted \n",
        "zipRef = zipfile.ZipFile(modelsPath + '/' + modelToLoad + '.zip', 'r')\n",
        "zipRef.extractall(modelDir + '/')\n",
        "zipRef.close()\n",
        "modelDir = localPath + '/' + 'training' + '/' + modelToLoad\n",
        "print('Model extraction successful')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model extraction successful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs-6YZo3x5vO"
      },
      "source": [
        "## 5. Dataset preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLFHdyO-x6yS"
      },
      "source": [
        "### Extract `zip` dataset locally\n",
        ">To access the dataset. The `zip` file is placed on Google Drive, but working there would be slow so needs to be extracted locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fbzspE0Qdw2",
        "outputId": "f1d19705-bc93-411b-998b-0603d3bf1ff1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Run it only when the dataset is not yet extracted \n",
        "zipRef = zipfile.ZipFile(dataPath + \"/datasetRecords.zip\", 'r')\n",
        "zipRef.extractall(localDataPath)\n",
        "zipRef.close()\n",
        "print('Dataset extraction successful')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset extraction successful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV"
      },
      "source": [
        "train_record_fname = '/content/data/trainDataset.tfrecord-?????-of-00010'\n",
        "validation_record_fname = '/content/data/validationDataset.tfrecord-?????-of-00001'\n",
        "test_record_fname = '/content/data/testDataset.tfrecord-?????-of-00001'\n",
        "label_map_pbtxt_fname = '/content/data/classes.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## 6. Modify configuration file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU"
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i8Z2pugLOUf"
      },
      "source": [
        "####Optional: Edit configuration file\n",
        ">Change config file based on selected model samples [here](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs).\n",
        ">\n",
        ">Add path to `tfrecod` files and to the `txt` file. Teaching parameters can be selected here (class number, batch size). Hyperparameters (augmentation, batch dropout, batch normalization, etc.) can be tuned here too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0oBwqzkO_Ag",
        "outputId": "d3aea6bf-2aef-4573-b2ce-5516cc6e2a93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(pipelineFilePath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O46kfvW9LWwD",
        "outputId": "f7f8783b-87b9-4922-bc0a-626824eaee71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile {pipelineFilePath}\n",
        "\n",
        "# SSDLite with Mobilenet v3 small feature extractor.\n",
        "# Trained on COCO14, initialized from scratch.\n",
        "# TPU-compatible.\n",
        "# Users should configure the fine_tune_checkpoint field in the train config as\n",
        "# well as the label_map_path and input_path fields in the train_input_reader and\n",
        "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
        "# should be configured.\n",
        "\n",
        "model {\n",
        "  ssd {\n",
        "    inplace_batchnorm_update: true\n",
        "    freeze_batchnorm: false\n",
        "    #change num_classes\n",
        "    num_classes: 3\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "        use_matmul_gather: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    encode_background_as_zeros: true\n",
        "    anchor_generator {\n",
        "      ssd_anchor_generator {\n",
        "        num_layers: 6\n",
        "        min_scale: 0.2\n",
        "        max_scale: 0.95\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        aspect_ratios: 3.0\n",
        "        aspect_ratios: 0.3333\n",
        "      }\n",
        "    }\n",
        "    image_resizer {\n",
        "      fixed_shape_resizer {\n",
        "        height: 320\n",
        "        width: 320\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      convolutional_box_predictor {\n",
        "        min_depth: 0\n",
        "        max_depth: 0\n",
        "        num_layers_before_predictor: 0\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 0.8\n",
        "        kernel_size: 3\n",
        "        use_depthwise: true\n",
        "        box_code_size: 4\n",
        "        apply_sigmoid_to_scores: false\n",
        "        class_prediction_bias_init: -4.6\n",
        "        conv_hyperparams {\n",
        "          activation: RELU_6,\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.00004\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            random_normal_initializer {\n",
        "              stddev: 0.03\n",
        "              mean: 0.0\n",
        "            }\n",
        "          }\n",
        "          batch_norm {\n",
        "            train: true,\n",
        "            scale: true,\n",
        "            center: true,\n",
        "            decay: 0.97,\n",
        "            epsilon: 0.001,\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'ssd_mobilenet_v3_small'\n",
        "      min_depth: 16\n",
        "      depth_multiplier: 1.0\n",
        "      use_depthwise: true\n",
        "      conv_hyperparams {\n",
        "        activation: RELU_6,\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            weight: 0.00004\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            stddev: 0.03\n",
        "            mean: 0.0\n",
        "          }\n",
        "        }\n",
        "        batch_norm {\n",
        "          train: true,\n",
        "          scale: true,\n",
        "          center: true,\n",
        "          decay: 0.97,\n",
        "          epsilon: 0.001,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    loss {\n",
        "      classification_loss {\n",
        "        weighted_sigmoid {\n",
        "        }\n",
        "      }\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      hard_example_miner {\n",
        "       num_hard_examples: 3000\n",
        "        iou_threshold: 0.99\n",
        "        loss_type: CLASSIFICATION\n",
        "        max_negatives_per_positive: 3\n",
        "        min_negatives_per_image: 3\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    normalize_loc_loss_by_codesize: true\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 1e-8\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 100\n",
        "        use_static_shapes: true\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  #change batch_size\n",
        "  batch_size: 32\n",
        "  sync_replicas: true\n",
        "  startup_delay_steps: 0\n",
        "  replicas_to_aggregate: 32\n",
        "  #change num_steps\n",
        "  num_steps: 90000\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    ssd_random_crop {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    random_adjust_contrast {\n",
        "    }\n",
        "  }\n",
        "  optimizer {\n",
        "    adam_optimizer: {\n",
        "      learning_rate: {\n",
        "        constant_learning_rate {\n",
        "          learning_rate: 0.00004\n",
        "        }\n",
        "      #  cosine_decay_learning_rate {\n",
        "      #    learning_rate_base: 0.00004\n",
        "      #    #change total_steps\n",
        "      #    total_steps: 40000\n",
        "      #    warmup_learning_rate: 0.00001\n",
        "      #    #change warmup_steps to include 1-2 epoch(s)\n",
        "      #    warmup_steps: 1500\n",
        "      #  }\n",
        "      }\n",
        "    }\n",
        "    use_moving_average: false\n",
        "  }\n",
        "  #Use it when you use a starter model\n",
        "  #fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
        "  #Use it when you continue your model's training\n",
        "  fine_tune_checkpoint: \"/content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-80000\"\n",
        "  from_detection_checkpoint: true\n",
        "  load_all_detection_checkpoint_vars: true\n",
        "  #change max_number_of_boxes\n",
        "  max_number_of_boxes: 100\n",
        "  unpad_groundtruth_tensors: false\n",
        "  freeze_variables: \".*FeatureExtractor*.\"\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    #change input_path\n",
        "    input_path: \"/content/data/trainDataset.tfrecord-?????-of-00010\"\n",
        "  }\n",
        "  #change label_map_path\n",
        "  label_map_path: \"/content/data/classes.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  #change num_examples\n",
        "  num_examples: 1000\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    #change input_path\n",
        "    input_path: \"/content/data/testDataset.tfrecord-?????-of-00001\"\n",
        "  }\n",
        "  #change label_map_path\n",
        "  label_map_path: \"/content/data/classes.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "outputId": "202a4328-8d2f-4572-b835-84178a590473",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cat {pipelineFilePath}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# SSDLite with Mobilenet v3 small feature extractor.\n",
            "# Trained on COCO14, initialized from scratch.\n",
            "# TPU-compatible.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "    #change num_classes\n",
            "    num_classes: 3\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 320\n",
            "        width: 320\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 3\n",
            "        use_depthwise: true\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        class_prediction_bias_init: -4.6\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.97,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v3_small'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      use_depthwise: true\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.97,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "       num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "        use_static_shapes: true\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  #change batch_size\n",
            "  batch_size: 32\n",
            "  sync_replicas: true\n",
            "  startup_delay_steps: 0\n",
            "  replicas_to_aggregate: 32\n",
            "  #change num_steps\n",
            "  num_steps: 90000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_adjust_contrast {\n",
            "    }\n",
            "  }\n",
            "  optimizer {\n",
            "    adam_optimizer: {\n",
            "      learning_rate: {\n",
            "        constant_learning_rate {\n",
            "          learning_rate: 0.00004\n",
            "        }\n",
            "      #  cosine_decay_learning_rate {\n",
            "      #    learning_rate_base: 0.00004\n",
            "      #    #change total_steps\n",
            "      #    total_steps: 40000\n",
            "      #    warmup_learning_rate: 0.00001\n",
            "      #    #change warmup_steps to include 1-2 epoch(s)\n",
            "      #    warmup_steps: 1500\n",
            "      #  }\n",
            "      }\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  #Use it when you use a starter model\n",
            "  #fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  #Use it when you continue your model's training\n",
            "  fine_tune_checkpoint: \"/content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-80000\"\n",
            "  from_detection_checkpoint: true\n",
            "  load_all_detection_checkpoint_vars: true\n",
            "  #change max_number_of_boxes\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "  freeze_variables: \".*FeatureExtractor*.\"\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    #change input_path\n",
            "    input_path: \"/content/data/trainDataset.tfrecord-?????-of-00010\"\n",
            "  }\n",
            "  #change label_map_path\n",
            "  label_map_path: \"/content/data/classes.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  #change num_examples\n",
            "  num_examples: 1000\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    #change input_path\n",
            "    input_path: \"/content/data/testDataset.tfrecord-?????-of-00001\"\n",
            "  }\n",
            "  #change label_map_path\n",
            "  label_map_path: \"/content/data/classes.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLumi7afLet1"
      },
      "source": [
        "### Optional: remove previous local model output directory to fresh start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB"
      },
      "source": [
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {modelDir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF"
      },
      "source": [
        "## 7. Run Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2PZs-mSCmO",
        "outputId": "2a6d3d1c-aec5-4780-dc25-311d37ed9ed6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "os.chdir(localPath)\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-27 17:17:52--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 3.229.170.137, 54.84.72.55, 18.214.118.253, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|3.229.170.137|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ngrok-stable-linux-amd64.zip\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab   5%[>                   ] 694.67K  3.38MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  35.2MB/s    in 0.4s    \n",
            "\n",
            "2020-05-27 17:17:52 (35.2 MB/s) - ngrok-stable-linux-amd64.zip saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M"
      },
      "source": [
        "LOG_DIR = modelDir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp"
      },
      "source": [
        "### Get Tensorboard link\n",
        ">Tensorboard magic: re-run field if an error occured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhPT9iPSJ6T",
        "outputId": "e4ebbd7b-4ccf-4afc-c6f9-a10c698697d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://30c419eb.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "## 8. Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4YeEkslnL52"
      },
      "source": [
        "### Move pipeline file to the train folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udLcg_xzeCgk"
      },
      "source": [
        "os.makedirs(modelDir, exist_ok=True)\n",
        "shutil.copyfile(pipelineFilePath, modelDir + '/pipeline.config')\n",
        "pipelineFilePath = modelDir + '/pipeline.config'\n",
        "print(pipelineFilePath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCQSTWLh239F"
      },
      "source": [
        "### Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "outputId": "37209a17-839a-4695-e859-c34a03646f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipelineFilePath} \\\n",
        "    --model_dir={modelDir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0527 17:23:25.317433 140028679079808 model_lib.py:717] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 90000\n",
            "I0527 17:23:25.317617 140028679079808 config_util.py:523] Maybe overwriting train_steps: 90000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0527 17:23:25.317689 140028679079808 config_util.py:523] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0527 17:23:25.317764 140028679079808 config_util.py:523] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0527 17:23:25.317818 140028679079808 config_util.py:523] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0527 17:23:25.317889 140028679079808 config_util.py:523] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0527 17:23:25.317959 140028679079808 config_util.py:533] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0527 17:23:25.318867 140028679079808 model_lib.py:733] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0527 17:23:25.318958 140028679079808 model_lib.py:768] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5aa4826a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0527 17:23:25.319319 140028679079808 estimator.py:212] Using config: {'_model_dir': '/content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5aa4826a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f5a8a790d08>) includes params argument, but params are not passed to Estimator.\n",
            "W0527 17:23:25.319483 140028679079808 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f5a8a790d08>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0527 17:23:25.320101 140028679079808 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0527 17:23:25.320258 140028679079808 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0527 17:23:25.320440 140028679079808 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0527 17:23:25.335838 140028679079808 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 10 to match input file shards.\n",
            "W0527 17:23:25.365975 140028679079808 dataset_builder.py:84] num_readers has been reduced to 10 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0527 17:23:25.371038 140028679079808 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0527 17:23:25.371172 140028679079808 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5a8a71d7f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0527 17:23:25.418449 140028679079808 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5a8a71d7f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "2020-05-27 17:23:25.447098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-27 17:23:25.459642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:25.460221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-27 17:23:25.460471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-27 17:23:25.461997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-27 17:23:25.463645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-27 17:23:25.464007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-27 17:23:25.469642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-27 17:23:25.489512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-27 17:23:25.496325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-27 17:23:25.496558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:25.497261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:25.497801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f5aafbf4378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0527 17:23:25.638188 140028679079808 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f5aafbf4378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0527 17:23:25.641316 140028679079808 deprecation.py:323] From /content/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0527 17:23:25.649862 140028679079808 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:198: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0527 17:23:25.717045 140028679079808 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:198: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0527 17:23:26.408583 140028679079808 deprecation.py:323] From /content/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:174: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W0527 17:23:26.727464 140028679079808 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:174: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0527 17:23:26.741400 140028679079808 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0527 17:23:26.754781 140028679079808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:23:28.819683 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:23:28.901469 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:23:28.983052 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:23:29.069628 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:23:29.155388 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:23:29.238631 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "W0527 17:23:29.446774 140028679079808 variables_helper.py:164] Variable [global_step] is not available in checkpoint\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0527 17:23:38.340294 140028679079808 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0527 17:23:38.341470 140028679079808 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0527 17:23:40.893945 140028679079808 monitored_session.py:240] Graph was finalized.\n",
            "2020-05-27 17:23:40.992766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-05-27 17:23:40.993278: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14a79c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-27 17:23:40.993319: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-27 17:23:41.127309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:41.128036: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14a7800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-27 17:23:41.128071: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-05-27 17:23:41.129406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:41.130018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-27 17:23:41.130103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-27 17:23:41.130121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-27 17:23:41.130134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-27 17:23:41.130149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-27 17:23:41.130163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-27 17:23:41.130177: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-27 17:23:41.130192: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-27 17:23:41.130280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:41.130925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:41.131479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-27 17:23:41.134789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-27 17:23:41.138949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-27 17:23:41.138980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-27 17:23:41.138988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-27 17:23:41.142195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:41.146331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:23:41.146940: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-27 17:23:41.146980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-80000\n",
            "I0527 17:23:41.149188 140028679079808 saver.py:1284] Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-80000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0527 17:23:48.351674 140028679079808 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0527 17:23:48.995882 140028679079808 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0527 17:23:49.263368 140028679079808 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 80000 into /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt.\n",
            "I0527 17:23:56.278660 140028679079808 basic_session_run_hooks.py:606] Saving checkpoints for 80000 into /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt.\n",
            "2020-05-27 17:24:03.344097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-27 17:24:07.365975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 2.3559313, step = 80000\n",
            "I0527 17:24:12.243211 140028679079808 basic_session_run_hooks.py:262] loss = 2.3559313, step = 80000\n",
            "INFO:tensorflow:global_step/sec: 2.43887\n",
            "I0527 17:24:53.244038 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.43887\n",
            "INFO:tensorflow:loss = 2.6508274, step = 80100 (41.004 sec)\n",
            "I0527 17:24:53.246741 140028679079808 basic_session_run_hooks.py:260] loss = 2.6508274, step = 80100 (41.004 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.68216\n",
            "I0527 17:25:30.527294 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.68216\n",
            "INFO:tensorflow:loss = 1.9450494, step = 80200 (37.283 sec)\n",
            "I0527 17:25:30.529684 140028679079808 basic_session_run_hooks.py:260] loss = 1.9450494, step = 80200 (37.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.61514\n",
            "I0527 17:26:08.766105 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.61514\n",
            "INFO:tensorflow:loss = 2.0221908, step = 80300 (38.238 sec)\n",
            "I0527 17:26:08.768005 140028679079808 basic_session_run_hooks.py:260] loss = 2.0221908, step = 80300 (38.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.56592\n",
            "I0527 17:26:47.738562 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.56592\n",
            "INFO:tensorflow:loss = 2.1114109, step = 80400 (38.972 sec)\n",
            "I0527 17:26:47.739803 140028679079808 basic_session_run_hooks.py:260] loss = 2.1114109, step = 80400 (38.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.57142\n",
            "I0527 17:27:26.627431 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.57142\n",
            "INFO:tensorflow:loss = 2.2238772, step = 80500 (38.905 sec)\n",
            "I0527 17:27:26.645224 140028679079808 basic_session_run_hooks.py:260] loss = 2.2238772, step = 80500 (38.905 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35258\n",
            "I0527 17:28:09.133922 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.35258\n",
            "INFO:tensorflow:loss = 2.2685144, step = 80600 (42.504 sec)\n",
            "I0527 17:28:09.148840 140028679079808 basic_session_run_hooks.py:260] loss = 2.2685144, step = 80600 (42.504 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.40745\n",
            "I0527 17:28:50.671722 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.40745\n",
            "INFO:tensorflow:loss = 2.0581706, step = 80700 (41.525 sec)\n",
            "I0527 17:28:50.673696 140028679079808 basic_session_run_hooks.py:260] loss = 2.0581706, step = 80700 (41.525 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.50171\n",
            "I0527 17:29:30.644392 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.50171\n",
            "INFO:tensorflow:loss = 2.2293894, step = 80800 (39.984 sec)\n",
            "I0527 17:29:30.658021 140028679079808 basic_session_run_hooks.py:260] loss = 2.2293894, step = 80800 (39.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.49116\n",
            "I0527 17:30:10.786317 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.49116\n",
            "INFO:tensorflow:loss = 2.1540601, step = 80900 (40.135 sec)\n",
            "I0527 17:30:10.793386 140028679079808 basic_session_run_hooks.py:260] loss = 2.1540601, step = 80900 (40.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.54999\n",
            "I0527 17:30:50.002017 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.54999\n",
            "INFO:tensorflow:loss = 1.8108727, step = 81000 (39.210 sec)\n",
            "I0527 17:30:50.003429 140028679079808 basic_session_run_hooks.py:260] loss = 1.8108727, step = 81000 (39.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.61667\n",
            "I0527 17:31:28.218443 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.61667\n",
            "INFO:tensorflow:loss = 1.9732243, step = 81100 (38.216 sec)\n",
            "I0527 17:31:28.219591 140028679079808 basic_session_run_hooks.py:260] loss = 1.9732243, step = 81100 (38.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.69125\n",
            "I0527 17:32:05.382373 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.69125\n",
            "INFO:tensorflow:loss = 1.7973307, step = 81200 (37.174 sec)\n",
            "I0527 17:32:05.393937 140028679079808 basic_session_run_hooks.py:260] loss = 1.7973307, step = 81200 (37.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.60032\n",
            "I0527 17:32:43.832851 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.60032\n",
            "INFO:tensorflow:loss = 2.2676609, step = 81300 (38.441 sec)\n",
            "I0527 17:32:43.834764 140028679079808 basic_session_run_hooks.py:260] loss = 2.2676609, step = 81300 (38.441 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.43812\n",
            "I0527 17:33:24.848025 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.43812\n",
            "INFO:tensorflow:loss = 1.984503, step = 81400 (41.020 sec)\n",
            "I0527 17:33:24.854488 140028679079808 basic_session_run_hooks.py:260] loss = 1.984503, step = 81400 (41.020 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 81488 into /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt.\n",
            "I0527 17:33:57.941403 140028679079808 basic_session_run_hooks.py:606] Saving checkpoints for 81488 into /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0527 17:33:57.992856 140028679079808 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5a28057908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0527 17:34:00.182015 140028679079808 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5a28057908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f5a2f49c9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0527 17:34:00.332292 140028679079808 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f5a2f49c9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0527 17:34:00.750378 140028679079808 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:34:02.798860 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:34:02.872235 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:34:02.944696 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:34:03.018240 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:34:03.095637 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0527 17:34:03.166440 140028679079808 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:828: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0527 17:34:03.716998 140028679079808 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:828: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0527 17:34:03.911865 140028679079808 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0527 17:34:04.417098 140028679079808 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-05-27T17:34:04Z\n",
            "I0527 17:34:04.433362 140028679079808 evaluation.py:255] Starting evaluation at 2020-05-27T17:34:04Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0527 17:34:04.852702 140028679079808 monitored_session.py:240] Graph was finalized.\n",
            "2020-05-27 17:34:04.853721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:34:04.854277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-27 17:34:04.854376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-27 17:34:04.854408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-27 17:34:04.854422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-27 17:34:04.854439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-27 17:34:04.854453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-27 17:34:04.854468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-27 17:34:04.854482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-27 17:34:04.854591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:34:04.855210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:34:04.855741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-27 17:34:04.855787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-27 17:34:04.855799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-27 17:34:04.855807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-27 17:34:04.855928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:34:04.856564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-27 17:34:04.857060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-81488\n",
            "I0527 17:34:04.858159 140028679079808 saver.py:1284] Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-81488\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0527 17:34:05.759193 140028679079808 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0527 17:34:05.883637 140028679079808 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 1440 images.\n",
            "I0527 17:35:23.613704 140024825771776 coco_evaluation.py:236] Performing evaluation on 1440 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0527 17:35:23.622226 140024825771776 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.12s)\n",
            "I0527 17:35:23.746709 140024825771776 coco_tools.py:137] DONE (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=13.67s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.85s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.505\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.294\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.423\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n",
            "INFO:tensorflow:Finished evaluation at 2020-05-27-17:35:40\n",
            "I0527 17:35:40.141879 140028679079808 evaluation.py:275] Finished evaluation at 2020-05-27-17:35:40\n",
            "INFO:tensorflow:Saving dict for global step 81488: DetectionBoxes_Precision/mAP = 0.29625162, DetectionBoxes_Precision/mAP (large) = 0.42155772, DetectionBoxes_Precision/mAP (medium) = 0.08214585, DetectionBoxes_Precision/mAP (small) = 0.00045042468, DetectionBoxes_Precision/mAP@.50IOU = 0.504579, DetectionBoxes_Precision/mAP@.75IOU = 0.29364488, DetectionBoxes_Recall/AR@1 = 0.29534122, DetectionBoxes_Recall/AR@10 = 0.4232678, DetectionBoxes_Recall/AR@100 = 0.46023065, DetectionBoxes_Recall/AR@100 (large) = 0.6101871, DetectionBoxes_Recall/AR@100 (medium) = 0.22956394, DetectionBoxes_Recall/AR@100 (small) = 0.013601734, Loss/classification_loss = 1.7713321, Loss/localization_loss = 0.21067277, Loss/regularization_loss = 0.029949257, Loss/total_loss = 2.0119526, global_step = 81488, learning_rate = 4e-05, loss = 2.0119526\n",
            "I0527 17:35:40.142219 140028679079808 estimator.py:2049] Saving dict for global step 81488: DetectionBoxes_Precision/mAP = 0.29625162, DetectionBoxes_Precision/mAP (large) = 0.42155772, DetectionBoxes_Precision/mAP (medium) = 0.08214585, DetectionBoxes_Precision/mAP (small) = 0.00045042468, DetectionBoxes_Precision/mAP@.50IOU = 0.504579, DetectionBoxes_Precision/mAP@.75IOU = 0.29364488, DetectionBoxes_Recall/AR@1 = 0.29534122, DetectionBoxes_Recall/AR@10 = 0.4232678, DetectionBoxes_Recall/AR@100 = 0.46023065, DetectionBoxes_Recall/AR@100 (large) = 0.6101871, DetectionBoxes_Recall/AR@100 (medium) = 0.22956394, DetectionBoxes_Recall/AR@100 (small) = 0.013601734, Loss/classification_loss = 1.7713321, Loss/localization_loss = 0.21067277, Loss/regularization_loss = 0.029949257, Loss/total_loss = 2.0119526, global_step = 81488, learning_rate = 4e-05, loss = 2.0119526\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 81488: /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-81488\n",
            "I0527 17:35:41.111853 140028679079808 estimator.py:2109] Saving 'checkpoint_path' summary for global step 81488: /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt-81488\n",
            "INFO:tensorflow:global_step/sec: 0.715139\n",
            "I0527 17:35:44.681012 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 0.715139\n",
            "INFO:tensorflow:loss = 2.078465, step = 81500 (139.832 sec)\n",
            "I0527 17:35:44.686877 140028679079808 basic_session_run_hooks.py:260] loss = 2.078465, step = 81500 (139.832 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.82016\n",
            "I0527 17:36:20.139895 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.82016\n",
            "INFO:tensorflow:loss = 2.1101046, step = 81600 (35.455 sec)\n",
            "I0527 17:36:20.141837 140028679079808 basic_session_run_hooks.py:260] loss = 2.1101046, step = 81600 (35.455 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.87941\n",
            "I0527 17:36:54.869206 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.87941\n",
            "INFO:tensorflow:loss = 2.6564026, step = 81700 (34.736 sec)\n",
            "I0527 17:36:54.877975 140028679079808 basic_session_run_hooks.py:260] loss = 2.6564026, step = 81700 (34.736 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.88063\n",
            "I0527 17:37:29.583783 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.88063\n",
            "INFO:tensorflow:loss = 2.0457356, step = 81800 (34.707 sec)\n",
            "I0527 17:37:29.584975 140028679079808 basic_session_run_hooks.py:260] loss = 2.0457356, step = 81800 (34.707 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.78538\n",
            "I0527 17:38:05.485476 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.78538\n",
            "INFO:tensorflow:loss = 2.2154157, step = 81900 (35.902 sec)\n",
            "I0527 17:38:05.487065 140028679079808 basic_session_run_hooks.py:260] loss = 2.2154157, step = 81900 (35.902 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.73506\n",
            "I0527 17:38:42.047880 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.73506\n",
            "INFO:tensorflow:loss = 2.7470038, step = 82000 (36.601 sec)\n",
            "I0527 17:38:42.088165 140028679079808 basic_session_run_hooks.py:260] loss = 2.7470038, step = 82000 (36.601 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.80932\n",
            "I0527 17:39:17.643632 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.80932\n",
            "INFO:tensorflow:loss = 2.417312, step = 82100 (35.560 sec)\n",
            "I0527 17:39:17.648102 140028679079808 basic_session_run_hooks.py:260] loss = 2.417312, step = 82100 (35.560 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.93483\n",
            "I0527 17:39:51.717090 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.93483\n",
            "INFO:tensorflow:loss = 2.272299, step = 82200 (34.070 sec)\n",
            "I0527 17:39:51.718432 140028679079808 basic_session_run_hooks.py:260] loss = 2.272299, step = 82200 (34.070 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.8799\n",
            "I0527 17:40:26.440647 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.8799\n",
            "INFO:tensorflow:loss = 2.1340714, step = 82300 (34.724 sec)\n",
            "I0527 17:40:26.442675 140028679079808 basic_session_run_hooks.py:260] loss = 2.1340714, step = 82300 (34.724 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.84071\n",
            "I0527 17:41:01.643075 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.84071\n",
            "INFO:tensorflow:loss = 1.9942625, step = 82400 (35.219 sec)\n",
            "I0527 17:41:01.661338 140028679079808 basic_session_run_hooks.py:260] loss = 1.9942625, step = 82400 (35.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.7749\n",
            "I0527 17:41:37.680234 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.7749\n",
            "INFO:tensorflow:loss = 2.2656164, step = 82500 (36.023 sec)\n",
            "I0527 17:41:37.684048 140028679079808 basic_session_run_hooks.py:260] loss = 2.2656164, step = 82500 (36.023 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.84178\n",
            "I0527 17:42:12.869471 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.84178\n",
            "INFO:tensorflow:loss = 2.5995297, step = 82600 (35.187 sec)\n",
            "I0527 17:42:12.871130 140028679079808 basic_session_run_hooks.py:260] loss = 2.5995297, step = 82600 (35.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.89271\n",
            "I0527 17:42:47.439114 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.89271\n",
            "INFO:tensorflow:loss = 2.348269, step = 82700 (34.570 sec)\n",
            "I0527 17:42:47.440679 140028679079808 basic_session_run_hooks.py:260] loss = 2.348269, step = 82700 (34.570 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.85037\n",
            "I0527 17:43:22.522291 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.85037\n",
            "INFO:tensorflow:loss = 1.5659964, step = 82800 (35.087 sec)\n",
            "I0527 17:43:22.527704 140028679079808 basic_session_run_hooks.py:260] loss = 1.5659964, step = 82800 (35.087 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 82901 into /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt.\n",
            "I0527 17:43:58.031136 140028679079808 basic_session_run_hooks.py:606] Saving checkpoints for 82901 into /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0527 17:44:00.104377 140028679079808 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 2.66075\n",
            "I0527 17:44:00.105497 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.66075\n",
            "INFO:tensorflow:loss = 1.8223449, step = 82900 (37.579 sec)\n",
            "I0527 17:44:00.106470 140028679079808 basic_session_run_hooks.py:260] loss = 1.8223449, step = 82900 (37.579 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.89446\n",
            "I0527 17:44:34.654352 140028679079808 basic_session_run_hooks.py:692] global_step/sec: 2.89446\n",
            "INFO:tensorflow:loss = 2.0643845, step = 83000 (34.550 sec)\n",
            "I0527 17:44:34.656876 140028679079808 basic_session_run_hooks.py:260] loss = 2.0643845, step = 83000 (34.550 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xByykvJn2u75"
      },
      "source": [
        "### Check output directory after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "outputId": "7a60be41-8cad-4db2-9fbe-7d119eb92391",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls {modelDir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1590424719.29eab163d8d4\n",
            "events.out.tfevents.1590474998.24980bca4a60\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-75846.data-00000-of-00001\n",
            "model.ckpt-75846.index\n",
            "model.ckpt-75846.meta\n",
            "model.ckpt-77141.data-00000-of-00001\n",
            "model.ckpt-77141.index\n",
            "model.ckpt-77141.meta\n",
            "model.ckpt-78364.data-00000-of-00001\n",
            "model.ckpt-78364.index\n",
            "model.ckpt-78364.meta\n",
            "model.ckpt-79808.data-00000-of-00001\n",
            "model.ckpt-79808.index\n",
            "model.ckpt-79808.meta\n",
            "model.ckpt-80000.data-00000-of-00001\n",
            "model.ckpt-80000.index\n",
            "model.ckpt-80000.meta\n",
            "pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U4PkjSQ3AIo"
      },
      "source": [
        "## 9. Export model\n",
        ">Save the model to Drive as a `zip` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MDLIkHA3B3W",
        "outputId": "d6f770b5-3fca-491d-a1f6-31dee6720452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.chdir(localPath)\n",
        "# Location where the exported model will be saved\n",
        "exportName = selectedModel + '_trained_at_' + '2020-05-26_adam_00004_const_lr_80k'\n",
        "print(exportName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVxZpU3NOIIj"
      },
      "source": [
        "### Optional: Zip all the training files to continue training later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbneB8AnhyOd",
        "outputId": "f6ed97d0-3c35-4e60-f7b3-cbfdea14a423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "exportToDrivePath = modelsPath + '/' + exportName\n",
        "outputTrainingFileName = localPath + '/' + exportName + '_training'\n",
        "os.makedirs(localPath + '/' + 'full_training')\n",
        "shutil.copytree(localPath + '/training', localPath + '/' + 'full_training' + '/' + exportName + '_training/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/full_training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM_rHTHsMY2o",
        "outputId": "006cc937-c5a0-48ea-8a1f-d44ce5ac270c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#ignore the error if zip creation is successful\n",
        "shutil.make_archive(outputTrainingFileName, 'zip', localPath + '/' + 'full_training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6srhQozOuVm",
        "outputId": "48830a13-9584-4f7d-a0e0-761914339bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "shutil.move(outputTrainingFileName + '.zip', modelsPath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Machine Learning/License plate detection/saved/models/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k_training.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90WGDg-5GYSF"
      },
      "source": [
        "### Optional: convert and save only the model to the local root folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "outputId": "d884e562-16da-450c-a9e1-3a01119a06ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "output_directory = '/content/fine_tuned_model/' + exportName\n",
        "\n",
        "lst = os.listdir(modelDir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(modelDir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipelineFilePath} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_training/model.ckpt-80000\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0526 15:20:31.969357 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:419: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0526 15:20:31.975577 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:419: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:138: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0526 15:20:31.975972 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:138: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:3030: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0526 15:20:32.005037 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:3030: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:608: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0526 15:20:32.028939 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:608: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0526 15:20:32.031293 140168632760192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0526 15:20:33.784585 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:157: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0526 15:20:33.794148 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:157: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0526 15:20:33.794327 140168632760192 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0526 15:20:33.870113 140168632760192 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0526 15:20:33.944451 140168632760192 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0526 15:20:34.121495 140168632760192 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0526 15:20:34.197347 140168632760192 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0526 15:20:34.275510 140168632760192 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:1106: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0526 15:20:34.502590 140168632760192 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:1106: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:295: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0526 15:20:34.690215 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:295: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:400: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0526 15:20:34.690463 140168632760192 deprecation.py:323] From /content/models/research/object_detection/exporter.py:400: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:432: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0526 15:20:34.693413 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:432: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:555: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0526 15:20:34.693578 140168632760192 deprecation.py:323] From /content/models/research/object_detection/exporter.py:555: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0526 15:20:34.694457 140168632760192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "206 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/935.56k params)\n",
            "  BoxPredictor_0 (--/12.12k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/3.47k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x288x12, 3.46k/3.46k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor_depthwise (--/2.59k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x288x1, 2.59k/2.59k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/3.47k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x288x12, 3.46k/3.46k params)\n",
            "    BoxPredictor_0/ClassPredictor_depthwise (--/2.59k params)\n",
            "      BoxPredictor_0/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_0/ClassPredictor_depthwise/depthwise_weights (3x3x288x1, 2.59k/2.59k params)\n",
            "  BoxPredictor_1 (--/19.06k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/6.94k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x288x24, 6.91k/6.91k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor_depthwise (--/2.59k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x288x1, 2.59k/2.59k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/6.94k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x288x24, 6.91k/6.91k params)\n",
            "    BoxPredictor_1/ClassPredictor_depthwise (--/2.59k params)\n",
            "      BoxPredictor_1/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_1/ClassPredictor_depthwise/depthwise_weights (3x3x288x1, 2.59k/2.59k params)\n",
            "  BoxPredictor_2 (--/33.84k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor_depthwise (--/4.61k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor_depthwise (--/4.61k params)\n",
            "      BoxPredictor_2/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_2/ClassPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "  BoxPredictor_3 (--/16.94k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_3/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_3/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "  BoxPredictor_4 (--/16.94k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor_depthwise (--/2.30k params)\n",
            "      BoxPredictor_4/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_4/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "  BoxPredictor_5 (--/8.50k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor_depthwise (--/1.15k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor_depthwise (--/1.15k params)\n",
            "      BoxPredictor_5/ClassPredictor_depthwise/BatchNorm (--/0 params)\n",
            "      BoxPredictor_5/ClassPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "  FeatureExtractor (--/828.16k params)\n",
            "    FeatureExtractor/MobilenetV3 (--/828.16k params)\n",
            "      FeatureExtractor/MobilenetV3/Conv (--/432 params)\n",
            "        FeatureExtractor/MobilenetV3/Conv/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/Conv/weights (3x3x3x16, 432/432 params)\n",
            "      FeatureExtractor/MobilenetV3/Conv_1 (--/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/Conv_1/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/Conv_1/weights (1x1x48x288, 13.82k/13.82k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv (--/680 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv/depthwise (--/144 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/depthwise/depthwise_weights (3x3x16x1, 144/144 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv/project (--/256 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/project/weights (1x1x16x16, 256/256 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite (--/280 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv (--/136 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv/biases (8, 8/8 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv/weights (1x1x16x8, 128/128 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv_1 (--/144 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/biases (16, 16/16 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/weights (1x1x8x16, 128/128 params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_1 (--/3.53k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise (--/648 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise/depthwise_weights (3x3x72x1, 648/648 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_1/expand (--/1.15k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/expand/weights (1x1x16x72, 1.15k/1.15k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_1/project (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_1/project/weights (1x1x72x24, 1.73k/1.73k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_10 (--/76.68k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise (--/7.20k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise/depthwise_weights (5x5x288x1, 7.20k/7.20k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/expand (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/expand/weights (1x1x48x288, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/project (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/project/weights (1x1x288x48, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite (--/41.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv (--/20.81k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv/biases (72, 72/72 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv/weights (1x1x288x72, 20.74k/20.74k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1 (--/21.02k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/biases (288, 288/288 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/weights (1x1x72x288, 20.74k/20.74k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_2 (--/5.02k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise (--/792 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise/depthwise_weights (3x3x88x1, 792/792 params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_2/expand (--/2.11k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/expand/weights (1x1x24x88, 2.11k/2.11k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_2/project (--/2.11k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_2/project/weights (1x1x88x24, 2.11k/2.11k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_3 (--/13.27k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise (--/2.40k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise/depthwise_weights (5x5x96x1, 2.40k/2.40k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/expand (--/2.30k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/expand/weights (1x1x24x96, 2.30k/2.30k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/project (--/3.84k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/project/weights (1x1x96x40, 3.84k/3.84k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite (--/4.73k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv (--/2.33k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv/biases (24, 24/24 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv/weights (1x1x96x24, 2.30k/2.30k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1 (--/2.40k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/biases (96, 96/96 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/weights (1x1x24x96, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_4 (--/56.22k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise (--/6.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise/depthwise_weights (5x5x240x1, 6.00k/6.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/expand (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/expand/weights (1x1x40x240, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/project (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/project/weights (1x1x240x40, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite (--/31.02k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv (--/15.42k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv/biases (64, 64/64 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv/weights (1x1x240x64, 15.36k/15.36k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1 (--/15.60k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/biases (240, 240/240 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/weights (1x1x64x240, 15.36k/15.36k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_5 (--/56.22k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise (--/6.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise/depthwise_weights (5x5x240x1, 6.00k/6.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/expand (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/expand/weights (1x1x40x240, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/project (--/9.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/project/weights (1x1x240x40, 9.60k/9.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite (--/31.02k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv (--/15.42k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv/biases (64, 64/64 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv/weights (1x1x240x64, 15.36k/15.36k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1 (--/15.60k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/biases (240, 240/240 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/weights (1x1x64x240, 15.36k/15.36k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_6 (--/21.39k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise (--/3.00k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise/depthwise_weights (5x5x120x1, 3.00k/3.00k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/expand (--/4.80k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/expand/weights (1x1x40x120, 4.80k/4.80k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/project (--/5.76k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/project/weights (1x1x120x48, 5.76k/5.76k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite (--/7.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv (--/3.87k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv/biases (32, 32/32 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv/weights (1x1x120x32, 3.84k/3.84k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1 (--/3.96k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1/biases (120, 120/120 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_6/squeeze_excite/Conv_1/weights (1x1x32x120, 3.84k/3.84k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_7 (--/29.13k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise (--/3.60k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise/depthwise_weights (5x5x144x1, 3.60k/3.60k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/expand (--/6.91k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/expand/weights (1x1x48x144, 6.91k/6.91k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/project (--/6.91k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/project/weights (1x1x144x48, 6.91k/6.91k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite (--/11.70k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv (--/5.80k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv/biases (40, 40/40 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv/weights (1x1x144x40, 5.76k/5.76k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1 (--/5.90k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1/biases (144, 144/144 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_7/squeeze_excite/Conv_1/weights (1x1x40x144, 5.76k/5.76k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_8 (--/76.68k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise (--/7.20k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise/depthwise_weights (5x5x288x1, 7.20k/7.20k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/expand (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/expand/weights (1x1x48x288, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/project (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/project/weights (1x1x288x48, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite (--/41.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv (--/20.81k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv/biases (72, 72/72 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv/weights (1x1x288x72, 20.74k/20.74k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1 (--/21.02k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1/biases (288, 288/288 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_8/squeeze_excite/Conv_1/weights (1x1x72x288, 20.74k/20.74k params)\n",
            "      FeatureExtractor/MobilenetV3/expanded_conv_9 (--/76.68k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise (--/7.20k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise/depthwise_weights (5x5x288x1, 7.20k/7.20k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/expand (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/expand/weights (1x1x48x288, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/project (--/13.82k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/project/weights (1x1x288x48, 13.82k/13.82k params)\n",
            "        FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite (--/41.83k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv (--/20.81k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv/biases (72, 72/72 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv/weights (1x1x288x72, 20.74k/20.74k params)\n",
            "          FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1 (--/21.02k params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1/biases (288, 288/288 params)\n",
            "            FeatureExtractor/MobilenetV3/expanded_conv_9/squeeze_excite/Conv_1/weights (1x1x72x288, 20.74k/20.74k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_2_1x1_256 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_2_1x1_256/weights (1x1x288x256, 73.73k/73.73k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512 (--/131.07k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128 (--/8.19k params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128/weights (1x1x64x128, 8.19k/8.19k params)\n",
            "      FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128_depthwise (--/576 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV3/layer_13_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
            "\n",
            "======================End of Report==========================\n",
            "206 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/21.69k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.40k/2.40k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.40k/2.40k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.40k/2.40k flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_2 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_2 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_1 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_3 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_3 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_3 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_2 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/GreaterEqual (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_2 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_1 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_1 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/sub_1 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/sub (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/mul (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_3 (300/300 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Sum (299/299 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less_1 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less_2 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_2 (100/100 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_1 (100/100 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (20/20 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (20/20 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:449: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0526 15:20:35.648171 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:449: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:359: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0526 15:20:36.438353 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:359: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-05-26 15:20:36.439712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-26 15:20:36.453379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.453916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-26 15:20:36.454213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 15:20:36.456549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-26 15:20:36.458475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-26 15:20:36.458849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-26 15:20:36.466037: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-26 15:20:36.467069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-26 15:20:36.474922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-26 15:20:36.475076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.475727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.476346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-26 15:20:36.484814: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-05-26 15:20:36.485103: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2290bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-26 15:20:36.485139: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-26 15:20:36.573440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.574127: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2290d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-26 15:20:36.574160: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-05-26 15:20:36.574317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.574886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-26 15:20:36.574950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 15:20:36.574992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-26 15:20:36.575008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-26 15:20:36.575022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-26 15:20:36.575039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-26 15:20:36.575052: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-26 15:20:36.575066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-26 15:20:36.575124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.575625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.576139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-26 15:20:36.576203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 15:20:36.577332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-26 15:20:36.577354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-26 15:20:36.577360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-26 15:20:36.577451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.577989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:36.578484: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-26 15:20:36.578519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_training/model.ckpt-80000\n",
            "I0526 15:20:36.580316 140168632760192 saver.py:1284] Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_training/model.ckpt-80000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0526 15:20:38.076395 140168632760192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-05-26 15:20:38.548755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:38.549362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-26 15:20:38.549452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 15:20:38.549479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-26 15:20:38.549501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-26 15:20:38.549523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-26 15:20:38.549563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-26 15:20:38.549605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-26 15:20:38.549629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-26 15:20:38.549745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:38.550437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:38.551005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-26 15:20:38.551045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-26 15:20:38.551072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-26 15:20:38.551082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-26 15:20:38.551189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:38.551766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:38.552389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_training/model.ckpt-80000\n",
            "I0526 15:20:38.553462 140168632760192 saver.py:1284] Restoring parameters from /content/training/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_training/model.ckpt-80000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0526 15:20:39.137994 140168632760192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0526 15:20:39.138255 140168632760192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 350 variables.\n",
            "I0526 15:20:39.501126 140168632760192 graph_util_impl.py:334] Froze 350 variables.\n",
            "INFO:tensorflow:Converted 350 variables to const ops.\n",
            "I0526 15:20:39.554823 140168632760192 graph_util_impl.py:394] Converted 350 variables to const ops.\n",
            "2020-05-26 15:20:39.648335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:39.648927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-26 15:20:39.649031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 15:20:39.649060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-26 15:20:39.649077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-26 15:20:39.649105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-26 15:20:39.649127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-26 15:20:39.649147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-26 15:20:39.649164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-26 15:20:39.649240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:39.649838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:39.650392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-26 15:20:39.650433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-26 15:20:39.650463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-26 15:20:39.650470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-26 15:20:39.650553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:39.651109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 15:20:39.651584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0526 15:20:40.106542 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:326: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0526 15:20:40.106987 140168632760192 deprecation.py:323] From /content/models/research/object_detection/exporter.py:326: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:332: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W0526 15:20:40.107371 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:332: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:335: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W0526 15:20:40.107511 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:335: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:340: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W0526 15:20:40.107669 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:340: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:342: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "W0526 15:20:40.107761 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:342: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0526 15:20:40.107997 140168632760192 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0526 15:20:40.108076 140168632760192 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/fine_tuned_model/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k/saved_model/saved_model.pb\n",
            "I0526 15:20:40.299122 140168632760192 builder_impl.py:425] SavedModel written to: /content/fine_tuned_model/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k/saved_model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:223: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0526 15:20:40.317552 140168632760192 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:223: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to /content/fine_tuned_model/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k/pipeline.config\n",
            "I0526 15:20:40.317744 140168632760192 config_util.py:225] Writing pipeline config file to /content/fine_tuned_model/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09AOThWkaQv"
      },
      "source": [
        "#### Zip the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDbg8IlZkOP7",
        "outputId": "849c033a-82f5-4c37-b2fa-a6bbcb3c10a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "exportToDrivePath = modelsPath + '/' + exportName\n",
        "outputFileName = localPath + '/' + exportName\n",
        "\n",
        "#ignore the error if zip creation is successful\n",
        "shutil.make_archive(outputFileName, 'zip', localPath + '/fine_tuned_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhS49yAiGqW3"
      },
      "source": [
        "#### Move the `zip`ped file to the Drive folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsOMNVqikOqX",
        "outputId": "1a57ebc1-913b-4254-cc0f-ed294d9c19dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "shutil.move(outputFileName + '.zip', modelsPath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Machine Learning/License plate detection/saved/models/ssd_mobilenet_v3_small_coco_trained_at_2020-05-26_adam_00004_const_lr_80k.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEdkQ5pQ1xtg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}