{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "r1ZCXk_5zZgV"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbj5UZmALRN3",
        "colab_type": "text"
      },
      "source": [
        "# TFlite converter notebook\n",
        "\n",
        ">This notebook uses Tensorflow Object Detection API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-u1TP5MLa0Q",
        "colab_type": "text"
      },
      "source": [
        "## 1. Prepare the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhnyGl4EuOfR",
        "colab_type": "text"
      },
      "source": [
        "### Clone MISC repos with Git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWcubyY-uLVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --q https://github.com/tensorflow/models.git\n",
        "!git clone --q https://github.com/tensorflow/tensorflow.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQzfWiW1u3Xs",
        "colab_type": "text"
      },
      "source": [
        "### Prepare and test Object Detection module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8YujrIiukZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/models/research')\n",
        "\n",
        "# compiling the proto buffers - more about them here: https://developers.google.com/protocol-buffers/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# export the PYTHONPATH environment variable with the reasearch and slim folders' paths\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-ODXrzfLeam",
        "colab_type": "text"
      },
      "source": [
        "### Import every dependency used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nyNwGIwouzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e8951683-b6f5-476e-d52c-bf7f814392a0"
      },
      "source": [
        "!python -m pip install numpy==1.17.4"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.17.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0MB 1.6MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.3\n",
            "    Uninstalling numpy-1.18.3:\n",
            "      Successfully uninstalled numpy-1.18.3\n",
            "Successfully installed numpy-1.17.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niYt8Nh8xogS",
        "colab_type": "code",
        "outputId": "00445186-3b1d-4cb2-e836-b7bc0f16f9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import xml.etree.ElementTree as ET\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import zipfile\n",
        "import imageio\n",
        "import urllib.request\n",
        "import urllib.parse\n",
        "import tarfile\n",
        "import glob\n",
        "import shutil\n",
        "import re\n",
        "import os\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from tensorflow.saved_model import tag_constants\n",
        "\n",
        "print(tf.__version__)\n",
        "print(np.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "1.17.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udbxAnFSPd-H",
        "colab_type": "text"
      },
      "source": [
        "### Install additional dependencies for Tensorflow Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCZVbYLsPbP7",
        "colab_type": "code",
        "outputId": "c5f81b72-cab7-4c2d-aa50-acd18de03ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip3 install -qq Cython contextlib2 pillow lxml matplotlib\n",
        "!pip3 install -qq pycocotools\n",
        "!pip3 install -U --user pip six numpy wheel setuptools mock 'future>=0.17.1'\n",
        "!pip3 install -U --user keras_applications --no-deps\n",
        "!pip3 install -U --user keras_preprocessing --no-deps"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144568 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/2e/df11ea7e23e7e761d484ed3740285a34e38548cf2bad2bed3dd5768ec8b9/pip-20.1-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 6.4MB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
            "Collecting numpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 7.0MB/s \n",
            "\u001b[?25hRequirement already up-to-date: wheel in /usr/local/lib/python3.6/dist-packages (0.34.2)\n",
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (46.1.3)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 38.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=683a03d0b874bf28e10addf2a42b72c739c551a019f99691d466957ccd5b29a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built future\n",
            "\u001b[31mERROR: tensorflow 1.15.2 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pip, six, numpy, mock, future\n",
            "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.6 are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.6 are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The scripts futurize and pasteurize are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed future-0.18.2 mock-4.0.2 numpy-1.18.4 pip-20.1 six-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
            "Requirement already up-to-date: keras_applications in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
            "Requirement already up-to-date: keras_preprocessing in /usr/local/lib/python3.6/dist-packages (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvSPYqgqu_2w",
        "colab_type": "code",
        "outputId": "6b9d19d6-f67c-47d6-b362-c4c936652c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "# test the model builder\n",
        "!python3 object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
            "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 17 tests in 0.234s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqQ_-EwWRG_U",
        "colab_type": "code",
        "outputId": "6819147c-eaf2-4ff3-f27c-8a9619b65c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May  3 20:31:56 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP7sthlzLj6n",
        "colab_type": "text"
      },
      "source": [
        "### Define paths\n",
        "\n",
        ">Paths defined to work remotely on google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD_LOMhLyZbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rootPath = '/content/drive/My Drive/Machine Learning/License plate detection'\n",
        "###\n",
        "dataPath = rootPath + '/data'\n",
        "logPath = rootPath + '/logs'\n",
        "\n",
        "savedPath = rootPath + '/saved'\n",
        "###\n",
        "modelsPath = savedPath + '/models'\n",
        "weightsPath = savedPath + '/weights'\n",
        "tflitePath = savedPath + '/tflite'\n",
        "earlyStoppingPath = savedPath + '/earlystopping'\n",
        "\n",
        "\n",
        "localPath = '/content'\n",
        "###\n",
        "localDataPath = localPath + '/data'\n",
        "startModelPath = localPath + '/start_model'\n",
        "endModelPath = localPath + '/end_model'\n",
        "localModelsPath = localPath + '/models/research'\n",
        "\n",
        "time = datetime.today().strftime('%Y-%m-%d-%H-%M')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsOpZvDeLp0X",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive to this Notebook instance\n",
        ">As the dataset has been prepared previously and updated to Google Drive, the model building and training process will be done there, not locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxIcETqwyjEJ",
        "colab_type": "code",
        "outputId": "b87681f4-fbf0-481f-fe20-1083f3d6b5c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "os.chdir(rootPath)\n",
        "# Show current directory\n",
        "!pwd"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Machine Learning/License plate detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1ZCXk_5zZgV",
        "colab_type": "text"
      },
      "source": [
        "## 5. Import saved model\n",
        "> The `zip` file is placed on Google Drive, but working there would be slow so needs to be extracted locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc12BiibJRK2",
        "colab_type": "code",
        "outputId": "494125a1-4171-446f-9c95-21ea707e8dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.chdir(localModelsPath)\n",
        "\n",
        "if (os.path.exists(startModelPath)):\n",
        "  shutil.rmtree(startModelPath)\n",
        "\n",
        "os.mkdir(startModelPath)\n",
        "os.chdir(startModelPath)\n",
        "\n",
        "# Name of the object detection model to load\n",
        "modelToLoad = 'ssd_mobilenet_v3_small_coco_trained_at_2020-05-03'\n",
        "\n",
        "# Path to the pipeline file in tensorflow object detection API\n",
        "pipelineFile = '/content/start_model/' + modelToLoad + '/pipeline.config'\n",
        "\n",
        "# Load the frozen model that is needed for inference\n",
        "# Run it only when the model is not yet extracted \n",
        "zipRef = zipfile.ZipFile(modelsPath + '/' + modelToLoad + '.zip', 'r')\n",
        "zipRef.extractall(startModelPath + '/')\n",
        "zipRef.close()\n",
        "print('Model extraction successful')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model extraction successful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmXsLgGhJfyQ",
        "colab_type": "text"
      },
      "source": [
        "## 9. Transform model to TFLite\n",
        "> Convert model to TensorFlow Lite model and write the `tflite` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1XQ8dp8auYL",
        "colab_type": "text"
      },
      "source": [
        "### Optional: open archived file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM72z-ljMmdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "\n",
        "os.chdir('/content/')\n",
        "fname = '/content/ssd_mobilenet_v2_oid_v4_2018_12_12.tar.gz'\n",
        "\n",
        "if fname.endswith(\"tar.gz\"):\n",
        "    tar = tarfile.open(fname, \"r:gz\")\n",
        "    tar.extractall()\n",
        "    tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLCb-_xla-q4",
        "colab_type": "text"
      },
      "source": [
        "### Run conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq9oLSpJpO2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exportName = 'mobilenet_v3' + '_trained_at_' + '2020-05-03'\n",
        "configFile = '/content/start_model/' + modelToLoad + '/pipeline.config'\n",
        "checkpointFiles = '/content/start_model/' + modelToLoad + '/model.ckpt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhbdVFM4zaUT",
        "colab_type": "code",
        "outputId": "1d11f02d-4064-4aab-d8ec-6e1da6692fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n",
        "--pipeline_config_path={configFile} \\\n",
        "--trained_checkpoint_prefix={checkpointFiles} \\\n",
        "--output_directory={endModelPath} \\\n",
        "--add_postprocessing_op True \\\n",
        "--max_detections 100"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0503 20:43:41.716217 140715550349184 module_wrapper.py:139] From /content/models/research/object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0503 20:43:41.720058 140715550349184 module_wrapper.py:139] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0503 20:43:41.720420 140715550349184 module_wrapper.py:139] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0503 20:43:41.724474 140715550349184 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0503 20:43:41.727690 140715550349184 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0503 20:43:44.162612 140715550349184 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0503 20:43:44.174949 140715550349184 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 20:43:44.175123 140715550349184 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 20:43:44.263265 140715550349184 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 20:43:44.351304 140715550349184 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 20:43:44.445582 140715550349184 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 20:43:44.543543 140715550349184 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0503 20:43:44.631798 140715550349184 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0503 20:43:44.741051 140715550349184 module_wrapper.py:139] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-05-03 20:43:44.742864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-03 20:43:44.786093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:44.787049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-03 20:43:44.787547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-03 20:43:45.054841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-03 20:43:45.194203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-03 20:43:45.219241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-03 20:43:45.497798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-03 20:43:45.554098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-03 20:43:46.060568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-03 20:43:46.060825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:46.061881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:46.062728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-03 20:43:46.097654: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-05-03 20:43:46.098026: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2101100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-03 20:43:46.098065: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-03 20:43:46.259078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:46.260229: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2100f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-03 20:43:46.260264: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-05-03 20:43:46.261545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:46.262445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-03 20:43:46.262534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-03 20:43:46.262586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-03 20:43:46.262629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-03 20:43:46.262685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-03 20:43:46.262734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-03 20:43:46.262775: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-03 20:43:46.262817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-03 20:43:46.262985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:46.263947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:46.264778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-03 20:43:46.269979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-03 20:43:46.271652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-03 20:43:46.271686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-03 20:43:46.271704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-03 20:43:46.274296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:46.275283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:46.276170: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-03 20:43:46.276228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0503 20:43:46.573976 140715550349184 module_wrapper.py:139] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0503 20:43:46.578085 140715550349184 module_wrapper.py:139] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:295: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0503 20:43:46.998669 140715550349184 module_wrapper.py:139] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:295: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0503 20:43:47.033992 140715550349184 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-05-03 20:43:47.597243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:47.598197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-05-03 20:43:47.598296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-03 20:43:47.598340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-03 20:43:47.598393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-03 20:43:47.598436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-03 20:43:47.598476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-03 20:43:47.598520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-03 20:43:47.598564: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-03 20:43:47.598695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:47.599656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:47.600509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-05-03 20:43:47.600562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-03 20:43:47.600586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-05-03 20:43:47.600601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-05-03 20:43:47.600748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:47.601683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-03 20:43:47.602550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/start_model/ssd_mobilenet_v3_small_coco_trained_at_2020-05-03/model.ckpt\n",
            "I0503 20:43:47.603853 140715550349184 saver.py:1284] Restoring parameters from /content/start_model/ssd_mobilenet_v3_small_coco_trained_at_2020-05-03/model.ckpt\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0503 20:43:54.175022 140715550349184 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0503 20:43:54.175319 140715550349184 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 350 variables.\n",
            "I0503 20:43:54.520842 140715550349184 graph_util_impl.py:334] Froze 350 variables.\n",
            "INFO:tensorflow:Converted 350 variables to const ops.\n",
            "I0503 20:43:54.570357 140715550349184 graph_util_impl.py:394] Converted 350 variables to const ops.\n",
            "2020-05-03 20:43:54.651678: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zcd500qT1HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/tensorflow\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5pl1BPDVlf9",
        "colab_type": "code",
        "outputId": "9d691738-401e-4f3d-9f41-c57534a36102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "source": [
        "BAZEL_VERSION = '3.0.0'\n",
        "!wget https://github.com/bazelbuild/bazel/releases/download/{BAZEL_VERSION}/bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh\n",
        "!chmod +x bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh\n",
        "!./bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-03 20:44:18--  https://github.com/bazelbuild/bazel/releases/download/3.0.0/bazel-3.0.0-installer-linux-x86_64.sh\n",
            "Resolving github.com (github.com)... 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/33b0e280-7818-11ea-8229-2d4e15ed8e7a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200503%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200503T204418Z&X-Amz-Expires=300&X-Amz-Signature=3ff47f28a6eb549b518a22ee800b32fd8dc5a240d0e5cebf54a8fbffd3cf2065&X-Amz-SignedHeaders=host&actor_id=0&repo_id=20773773&response-content-disposition=attachment%3B%20filename%3Dbazel-3.0.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-05-03 20:44:18--  https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/33b0e280-7818-11ea-8229-2d4e15ed8e7a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200503%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200503T204418Z&X-Amz-Expires=300&X-Amz-Signature=3ff47f28a6eb549b518a22ee800b32fd8dc5a240d0e5cebf54a8fbffd3cf2065&X-Amz-SignedHeaders=host&actor_id=0&repo_id=20773773&response-content-disposition=attachment%3B%20filename%3Dbazel-3.0.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.84.115\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.84.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42927842 (41M) [application/octet-stream]\n",
            "Saving to: ‘bazel-3.0.0-installer-linux-x86_64.sh’\n",
            "\n",
            "bazel-3.0.0-install 100%[===================>]  40.94M  20.9MB/s    in 2.0s    \n",
            "\n",
            "2020-05-03 20:44:20 (20.9 MB/s) - ‘bazel-3.0.0-installer-linux-x86_64.sh’ saved [42927842/42927842]\n",
            "\n",
            "Bazel installer\n",
            "---------------\n",
            "\n",
            "Bazel is bundled with software licensed under the GPLv2 with Classpath exception.\n",
            "You can find the sources next to the installer on our release page:\n",
            "   https://github.com/bazelbuild/bazel/releases\n",
            "\n",
            "# \n",
            "\n",
            "## Build information\n",
            "   - [Commit](https://github.com/bazelbuild/bazel/commit/eea58d1)\n",
            "Uncompressing.......\n",
            "\n",
            "Bazel is now installed!\n",
            "\n",
            "Make sure you have \"/usr/local/bin\" in your path. You can also activate bash\n",
            "completion by adding the following line to your ~/.bashrc:\n",
            "  source /usr/local/lib/bazel/bin/bazel-complete.bash\n",
            "\n",
            "See http://bazel.build/docs/getting-started.html to start a new project!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mseINmOzCzBO",
        "colab_type": "code",
        "outputId": "12d4a1bf-ec63-4d9a-dbae-afd94b40c776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!bazel run -c opt tensorflow/lite/toco:toco -- \\\n",
        "--input_file='/content/end_model/tflite_graph.pb' \\\n",
        "--output_file='/content/end_model/detector.tflite' \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--mean_values=128 \\\n",
        "--change_concat_input_ranges=false \\\n",
        "--allow_custom_ops\n",
        "\n",
        "if not os.path.exists(os.path.join(tflitePath + \"/\" + exportName + \"/\")):\n",
        "    os.makedirs(os.path.join(tflitePath + \"/\" + exportName + \"/\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO: \u001b[0mOptions provided by the client:\n",
            "  Inherited 'common' options: --isatty=1 --terminal_columns=0\n",
            "\u001b[32mINFO: \u001b[0mReading rc options for 'run' from /content/tensorflow/.bazelrc:\n",
            "  Inherited 'common' options: --experimental_repo_remote_exec\n",
            "\u001b[32mINFO: \u001b[0mReading rc options for 'run' from /content/tensorflow/.bazelrc:\n",
            "  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2\n",
            "\u001b[32mINFO: \u001b[0mFound applicable config definition build:v2 in file /content/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\n",
            "\u001b[32mINFO: \u001b[0mFound applicable config definition build:linux in file /content/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\n",
            "\u001b[32mINFO: \u001b[0mFound applicable config definition build:dynamic_kernels in file /content/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\n",
            "\u001b[32mLoading:\u001b[0m \n",
            "\r\u001b[1A\u001b[K\u001b[32mLoading:\u001b[0m 0 packages loaded\n",
            "\r\u001b[1A\u001b[K\u001b[33mDEBUG: \u001b[0mRule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded)\n",
            "\r\u001b[1A\u001b[K\u001b[33mDEBUG: \u001b[0mCall stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at /root/.cache/bazel/_bazel_root/889612a75a81b3d8b4ed860522ba4e34/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):\n",
            " - <builtin>\n",
            " - /root/.cache/bazel/_bazel_root/889612a75a81b3d8b4ed860522ba4e34/external/bazel_toolchains/repositories/repositories.bzl:37:9\n",
            " - /content/tensorflow/WORKSPACE:37:1\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded)\n",
            "\r\u001b[1A\u001b[K\u001b[35mWARNING: \u001b[0mDownload from https://storage.googleapis.com/mirror.tensorflow.org/github.com/bazelbuild/rules_swift/archive/3eeeb53cebda55b349d64c9fc144e18c5f7c0eb8.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded)\n",
            "\r\u001b[1A\u001b[K\u001b[35mWARNING: \u001b[0mDownload from https://storage.googleapis.com/mirror.tensorflow.org/github.com/bazelbuild/rules_apple/archive/5131f3d46794bf227d296c82f30c2499c9de3c5b.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded)\n",
            "\r\u001b[1A\u001b[K\u001b[35mWARNING: \u001b[0mDownload from https://storage.googleapis.com/mirror.tensorflow.org/github.com/bazelbuild/apple_support/archive/501b4afb27745c4813a88ffa28acd901408014e4.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded)\n",
            "\r\u001b[1A\u001b[K\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (0 packages loaded, 0 targets co\\\n",
            "nfigured)\n",
            "    Fetching @aws-c-event-stream; fetching 13s\n",
            "\u001b[35mWARNING: \u001b[0mDownload from https://mirror.bazel.build/github.com/aws/aws-sdk-cpp/archive/1.7.266.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (1 packages loaded, 4 targets co\\\n",
            "\u001b[35mWARNING: \u001b[0m/content/tensorflow/tensorflow/core/BUILD:1794:1: in linkstatic attribute of cc_library rule //tensorflow/core:lib_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'cc_library', the error might have been caused by the macro implementation\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (1 packages loaded, 1000 targets\\\n",
            "\u001b[35mWARNING: \u001b[0m/content/tensorflow/tensorflow/core/BUILD:2239:1: in linkstatic attribute of cc_library rule //tensorflow/core:framework_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (1 packages loaded, 1002 targets\\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //tensorflow/lite/toco:toco (1 packages loaded, 1012 targets\\\n",
            "\u001b[32mINFO: \u001b[0mAnalyzed target //tensorflow/lite/toco:toco (1 packages loaded, 1012 targets configured).\n",
            "\u001b[32mINFO: \u001b[0mFound 1 target...\n",
            "\u001b[32m[19 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    Action tensorflow/core/util/version_info.cc; 0s local\n",
            "\u001b[32m[19 / 2,082]\u001b[0m 2 actions running\n",
            "    Action tensorflow/core/util/version_info.cc; 0s local\n",
            "\u001b[32m[20 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc; 0s local\n",
            "\u001b[32m[20 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc; 1s local\n",
            "\u001b[32m[21 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[21 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[21 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[22 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[22 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[22 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s local\n",
            "\u001b[32m[23 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[24 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[25 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[25 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[25 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[25 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[25 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s local\n",
            "\u001b[32m[26 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s local\n",
            "\u001b[32m[26 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s local\n",
            "\u001b[32m[27 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[27 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[27 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[28 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[29 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[30 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[30 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[30 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[31 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[31 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[31 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[32 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[32 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[33 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[34 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[34 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[35 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[35 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[35 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s local\n",
            "\u001b[32m[36 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 4s local\n",
            "\u001b[32m[37 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[37 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[37 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[38 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[38 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[39 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[39 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[40 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s local\n",
            "\u001b[32m[41 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s local\n",
            "\u001b[32m[42 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[42 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[43 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[43 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[44 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[44 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[45 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[45 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[46 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[46 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[46 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[47 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 3s local\n",
            "\u001b[32m[47 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s local\n",
            "\u001b[32m[48 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[48 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[49 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[50 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[50 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[50 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[50 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[50 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[51 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[51 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s local\n",
            "\u001b[32m[51 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s local\n",
            "\u001b[32m[52 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[53 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[53 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[53 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[54 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[54 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[55 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[55 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[56 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[57 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[57 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[58 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[58 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[58 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s local\n",
            "\u001b[32m[59 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[61 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[61 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[64 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling external/zlib/gzwrite.c [for host]; 0s local\n",
            "\u001b[32m[65 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling external/com_googlesource_code_re2/re2/re2.cc; 0s local\n",
            "\u001b[32m[67 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    Compiling external/com_googlesource_code_re2/re2/re2.cc; 0s local\n",
            "\u001b[32m[67 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling external/com_googlesource_code_re2/re2/re2.cc; 0s local\n",
            "\u001b[32m[68 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling external/com_googlesource_code_re2/re2/re2.cc; 1s local\n",
            "\u001b[32m[69 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    Compiling external/com_googlesource_code_re2/re2/re2.cc; 1s local\n",
            "\u001b[32m[70 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    Compiling external/com_googlesource_code_re2/re2/re2.cc; 1s local\n",
            "\u001b[32m[70 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling external/com_googlesource_code_re2/re2/re2.cc; 2s local\n",
            "\u001b[32m[71 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[71 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[71 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[72 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[73 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling external/com_googlesource_code_re2/re2/simplify.cc; 0s local\n",
            "\u001b[32m[73 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling external/com_googlesource_code_re2/re2/simplify.cc; 1s local\n",
            "\u001b[32m[74 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[74 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[75 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s local\n",
            "\u001b[32m[75 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[75 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[77 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s local\n",
            "\u001b[32m[77 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s local\n",
            "\u001b[32m[78 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[78 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s local\n",
            "\u001b[32m[78 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s local\n",
            "\u001b[32m[79 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s local\n",
            "\u001b[32m[79 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s local\n",
            "\u001b[32m[80 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 4s local\n",
            "\u001b[32m[80 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s local\n",
            "\u001b[32m[80 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 5s local\n",
            "\u001b[32m[81 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 6s local\n",
            "\u001b[32m[82 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 7s local\n",
            "\u001b[32m[82 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 7s local\n",
            "\u001b[32m[83 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 7s local\n",
            "\u001b[32m[83 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 8s local\n",
            "\u001b[32m[84 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_absl//absl/base:raw_logging_internal; 0s local\n",
            "\u001b[32m[85 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_absl//absl/base:base; 0s local\n",
            "\u001b[32m[86 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_absl//absl/base:base; 0s local\n",
            "\u001b[32m[88 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_absl//absl/strings:strings; 0s local\n",
            "\u001b[32m[90 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_absl//absl/base:base; 0s local\n",
            "\u001b[32m[91 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[92 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[92 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[92 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[93 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[94 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[94 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s local\n",
            "\u001b[32m[95 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 5s local\n",
            "\u001b[32m[95 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s local\n",
            "\u001b[32m[95 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 6s local\n",
            "\u001b[32m[95 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 7s local\n",
            "\u001b[32m[96 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 8s local\n",
            "\u001b[32m[97 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 8s local\n",
            "\u001b[32m[98 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 9s local\n",
            "\u001b[32m[98 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 9s local\n",
            "\u001b[32m[99 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 10s local\n",
            "\u001b[32m[99 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 10s local\n",
            "\u001b[32m[100 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[100 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[100 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[101 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[101 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[101 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[102 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[102 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s local\n",
            "\u001b[32m[103 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[103 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[104 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[104 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[105 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    Compiling external/nsync/internal/common.c; 0s local\n",
            "\u001b[32m[106 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[106 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[107 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[107 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[108 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[108 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[109 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[109 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[110 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 4s local\n",
            "\u001b[32m[110 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s local\n",
            "\u001b[32m[111 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[111 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[112 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[113 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[114 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[114 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[115 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[115 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s local\n",
            "\u001b[32m[115 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s local\n",
            "\u001b[32m[116 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 5s local\n",
            "\u001b[32m[117 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 5s local\n",
            "\u001b[32m[117 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s local\n",
            "\u001b[32m[117 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 6s local\n",
            "\u001b[32m[118 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[118 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[119 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[119 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[120 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[120 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[120 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[121 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[122 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[123 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @double_conversion//:double-conversion; 0s local\n",
            "\u001b[32m[123 / 2,082]\u001b[0m 2 actions running\n",
            "    @double_conversion//:double-conversion; 0s local\n",
            "\u001b[32m[124 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[126 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[126 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[127 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[127 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[129 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling tensorflow/core/platform/strcat.cc; 0s local\n",
            "\u001b[32m[129 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling tensorflow/core/platform/strcat.cc; 0s local\n",
            "\u001b[32m[130 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling tensorflow/core/platform/numbers.cc; 0s local\n",
            "\u001b[32m[130 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling tensorflow/core/platform/numbers.cc; 1s local\n",
            "\u001b[32mINFO: \u001b[0mFrom Compiling tensorflow/core/platform/numbers.cc:\n",
            "\u001b[32m[130 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling tensorflow/core/platform/numbers.cc; 2s local\n",
            "tensorflow/core/platform/numbers.cc: In function 'std::__cxx11::string tensorflow::strings::HumanReadableNumBytes(tensorflow::int64)':\n",
            "tensorflow/core/platform/numbers.cc:459:8: warning: '%lld' directive output may be truncated writing between 1 and 19 bytes into a region of size between 7 and 8 [-Wformat-truncation=]\n",
            " string HumanReadableNumBytes(int64 num_bytes) {\n",
            "        ^~~~~~~~~~~~~~~~~~~~~\n",
            "tensorflow/core/platform/numbers.cc:459:8: note: directive argument in the range [0, 9223372036854775807]\n",
            "In file included from /usr/include/stdio.h:862:0,\n",
            "                 from /usr/include/c++/7/cstdio:42,\n",
            "                 from /usr/include/c++/7/ext/string_conversions.h:43,\n",
            "                 from /usr/include/c++/7/bits/basic_string.h:6361,\n",
            "                 from /usr/include/c++/7/string:52,\n",
            "                 from ./tensorflow/core/platform/numbers.h:19,\n",
            "                 from tensorflow/core/platform/numbers.cc:15:\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:65:44: note: '__builtin_snprintf' output between 3 and 22 bytes into a destination of size 8\n",
            "        __bos (__s), __fmt, __va_arg_pack ());\n",
            "                                            ^\n",
            "\u001b[32m[130 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling tensorflow/core/platform/numbers.cc; 2s local\n",
            "\u001b[32m[132 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling external/nsync/platform/posix/src/per_thread_waiter.c; 0s local\n",
            "\u001b[32m[133 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @nsync//:nsync_cpp; 0s local\n",
            "\u001b[32m[134 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[135 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[135 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[136 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[138 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[138 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[139 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[139 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[139 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[140 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[140 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[140 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[141 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[141 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[142 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 4s local\n",
            "\u001b[32m[142 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s local\n",
            "\u001b[32m[143 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 4s local\n",
            "\u001b[32m[143 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s local\n",
            "\u001b[32m[144 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 5s local\n",
            "\u001b[32m[144 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s local\n",
            "\u001b[32m[145 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[146 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling external/nsync/platform/c++11/src/nsync_panic.cc; 0s local\n",
            "\u001b[32m[147 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[147 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s local\n",
            "\u001b[32m[147 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s local\n",
            "\u001b[32m[147 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[148 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[148 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s local\n",
            "\u001b[32m[149 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 3s local\n",
            "\u001b[32m[149 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s local\n",
            "\u001b[32m[150 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[151 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling external/nsync/internal/common.c; 0s local\n",
            "\u001b[32m[152 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[152 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s local\n",
            "\u001b[32m[153 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s local\n",
            "\u001b[32m[153 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 2s local\n",
            "\u001b[32m[154 / 2,082]\u001b[0m 2 actions running\n",
            "    Compiling external/zlib/inflate.c; 0s local\n",
            "\u001b[32m[155 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[155 / 2,082]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s local\n",
            "\u001b[32m[156 / 2,082]\u001b[0m 2 actions, 1 running\n",
            "    Compiling tensorflow/core/platform/protobuf_util.cc; 0s local\n",
            "    [Scann] @com_google_protobuf//:protobuf_lite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI-a3i6STPLF",
        "colab_type": "text"
      },
      "source": [
        "### Create generated `tflite` model visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjOZFxQsFYZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!bazel run -c opt tensorflow/lite/tools:visualize -- \\\n",
        "'/content/end_model/detector.tflite' \\\n",
        "'/content/end_model/detector_visualized.html'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcMfC7ZoSdtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.copy('/content/end_model/detector.tflite', os.path.join(tflitePath + \"/\" + exportName + \"/\" + \"model.tflite\"))\n",
        "shutil.copy('/content/end_model/detector_visualized.html', os.path.join(tflitePath + \"/\" + exportName + \"/\" + \"detector_visualized.html\"))\n",
        "#shutil.copy('/content/data/classes.pbtxt', os.path.join(tflitePath + \"/\" + exportName + \"/\" + \"labelmap.txt\"))\n",
        "\n",
        "print('TFLite model generated and saved successfully. File location: %s' %(tflitePath + \"/\" + exportName + \"/\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JafOR0KmTQtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}