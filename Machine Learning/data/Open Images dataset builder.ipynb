{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Open Images dataset builder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtJeYzpKzN9v",
        "colab_type": "text"
      },
      "source": [
        "# Dataset creator Notebook\n",
        "\n",
        ">This notebook downloads specific classes from the Open Images dataset with the desired cardinality. Then, it transform this set into .tfrecord format to make it possible to use with Tensorflow Object Detection API.\n",
        ">\n",
        ">The downloaded set can be saved into the mounted Drive folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOzEm7240GcG",
        "colab_type": "text"
      },
      "source": [
        "## 1. Prepare the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_WyEZ940axq",
        "colab_type": "text"
      },
      "source": [
        "### Clone MISC repos with Git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbW-Udpp4izl",
        "colab_type": "code",
        "outputId": "0a445d22-e49e-43db-98e4-1356a436bb70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/EscVM/OIDv4_ToolKit.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OIDv4_ToolKit'...\n",
            "remote: Enumerating objects: 422, done.\u001b[K\n",
            "remote: Total 422 (delta 0), reused 0 (delta 0), pack-reused 422\u001b[K\n",
            "Receiving objects: 100% (422/422), 34.08 MiB | 16.45 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieL7Vuv3gQO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --q https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI6XEy4F0ljR",
        "colab_type": "text"
      },
      "source": [
        "### Prepare and test Object Detection module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjVoK_lkgQVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/models/research')\n",
        "\n",
        "# compiling the proto buffers - more about them here: https://developers.google.com/protocol-buffers/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# export the PYTHONPATH environment variable with the reasearch and slim folders' paths\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACDlDmr-gjZB",
        "colab_type": "code",
        "outputId": "e6f365e1-89e9-4805-a23c-99070484437d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "# test the model builder\n",
        "!python3 object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
            "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 17 tests in 0.176s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_MlKGok0PBi",
        "colab_type": "text"
      },
      "source": [
        "### Import required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifQ3zcz03s2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "import zipfile\n",
        "import shutil\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import contextlib2\n",
        "import gc\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.dataset_tools import tf_record_creation_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXq0JpK31CjO",
        "colab_type": "text"
      },
      "source": [
        "### Define paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBnx0Ibd2sG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rootPath = '/content/drive/My Drive/Machine Learning/License plate detection'\n",
        "dataPath = rootPath + '/data'\n",
        "\n",
        "localPath = '/content'\n",
        "rootOIDv4Path = localPath + '/OIDv4_ToolKit'\n",
        "datasetRootPath = rootOIDv4Path + '/OID'\n",
        "generatedDatasetPath = localPath + '/generated'\n",
        "recordsPath = generatedDatasetPath + '/records'\n",
        "csvPath = generatedDatasetPath + '/csv'\n",
        "\n",
        "if not os.path.exists(recordsPath):\n",
        "  os.makedirs(recordsPath)\n",
        "\n",
        "if not os.path.exists(csvPath):\n",
        "  os.makedirs(csvPath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qz44ln_0Nkc",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive to this Notebook instance\n",
        ">As the dataset has been prepared previously and updated to Google Drive, the model building and training process will be done there, not locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NstP48rK3t7s",
        "colab_type": "code",
        "outputId": "d5f23c43-5c24-48ee-91df-781f3cb7968b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir(localPath)\n",
        "# Show current directory\n",
        "!pwd"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNXxnxdV03oM",
        "colab_type": "text"
      },
      "source": [
        "### Install OIDv4 requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXKClf7R4rky",
        "colab_type": "code",
        "outputId": "b88d0483-a642-44aa-91cc-955a8042d8aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "os.chdir(rootOIDv4Path)\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.25.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.17.5)\n",
            "Collecting awscli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/ad/891570946642748fab392d770197ac7c2cfdec93e87a27bf3bbfa864694f/awscli-1.18.16-py2.py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (4.28.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (4.1.2.30)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 1)) (2018.9)\n",
            "Collecting botocore==1.15.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/fb/6b3e135e09ec38051d903f1ff6509309a5731e57c95dae2daeb0b70cf52c/botocore-1.15.16-py2.py3-none-any.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 59.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML<5.4,>=3.10; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from awscli->-r requirements.txt (line 3)) (3.13)\n",
            "Collecting colorama<0.4.4,>=0.2.5; python_version != \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting rsa<=3.5.0,>=3.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from awscli->-r requirements.txt (line 3)) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli->-r requirements.txt (line 3)) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.15.16->awscli->-r requirements.txt (line 3)) (0.9.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli->-r requirements.txt (line 3)) (0.4.8)\n",
            "\u001b[31mERROR: boto3 1.11.15 has requirement botocore<1.15.0,>=1.14.15, but you'll have botocore 1.15.16 which is incompatible.\u001b[0m\n",
            "Installing collected packages: botocore, colorama, rsa, awscli\n",
            "  Found existing installation: botocore 1.14.15\n",
            "    Uninstalling botocore-1.14.15:\n",
            "      Successfully uninstalled botocore-1.14.15\n",
            "  Found existing installation: rsa 4.0\n",
            "    Uninstalling rsa-4.0:\n",
            "      Successfully uninstalled rsa-4.0\n",
            "Successfully installed awscli-1.18.16 botocore-1.15.16 colorama-0.4.3 rsa-3.4.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "botocore",
                  "rsa"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5U_RJtv20UK",
        "colab_type": "text"
      },
      "source": [
        "### Extract a previously downloaded raw dataset from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CozVAFBQWZO",
        "colab_type": "code",
        "outputId": "e14ec7d5-d423-4899-e75f-cbfad758502e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run it only when the dataset is not yet extracted \n",
        "zipRef = zipfile.ZipFile(dataPath + \"/dummyDataset.zip\", 'r')\n",
        "zipRef.extractall(localPath + \"/data\")\n",
        "zipRef.close()\n",
        "print('Dataset extraction successful')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset extraction successful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbhbpg7W1LBJ",
        "colab_type": "text"
      },
      "source": [
        "##2. Use OIDv4 downloader to get the desired images\n",
        ">This part downloads the images and their annotations as the raw dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9jHtrta1vdM",
        "colab_type": "text"
      },
      "source": [
        "### Show available OIDv4 commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uodxYum5iPz",
        "colab_type": "code",
        "outputId": "11ca3078-0f4b-4381-ddf4-c26462ad48a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "!python3 main.py -h"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: main.py [-h] [--Dataset /path/to/OID/csv/] [-y]\n",
            "               [--classes list of classes [list of classes ...]]\n",
            "               [--type_csv 'train' or 'validation' or 'test' or 'all']\n",
            "               [--sub Subset of human verified images or machine generated h or m)]\n",
            "               [--image_IsOccluded 1 or 0] [--image_IsTruncated 1 or 0]\n",
            "               [--image_IsGroupOf 1 or 0] [--image_IsDepiction 1 or 0]\n",
            "               [--image_IsInside 1 or 0] [--multiclasses 0 (default or 1]\n",
            "               [--n_threads [default 20]] [--noLabels]\n",
            "               [--limit integer number]\n",
            "               <command> 'downloader', 'visualizer' or 'ill_downloader'.\n",
            "\n",
            "Open Image Dataset Downloader\n",
            "\n",
            "positional arguments:\n",
            "  <command> 'downloader', 'visualizer' or 'ill_downloader'.\n",
            "                        'downloader', 'visualizer' or 'ill_downloader'.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --Dataset /path/to/OID/csv/\n",
            "                        Directory of the OID dataset folder\n",
            "  -y, --yes             ans Yes to possible download of missing files\n",
            "  --classes list of classes [list of classes ...]\n",
            "                        Sequence of 'strings' of the wanted classes\n",
            "  --type_csv 'train' or 'validation' or 'test' or 'all'\n",
            "                        From what csv search the images\n",
            "  --sub Subset of human verified images or machine generated (h or m)\n",
            "                        Download from the human verified dataset or from the\n",
            "                        machine generated one.\n",
            "  --image_IsOccluded 1 or 0\n",
            "                        Optional characteristic of the images. Indicates that\n",
            "                        the object is occluded by another object in the image.\n",
            "  --image_IsTruncated 1 or 0\n",
            "                        Optional characteristic of the images. Indicates that\n",
            "                        the object extends beyond the boundary of the image.\n",
            "  --image_IsGroupOf 1 or 0\n",
            "                        Optional characteristic of the images. Indicates that\n",
            "                        the box spans a group of objects (min 5).\n",
            "  --image_IsDepiction 1 or 0\n",
            "                        Optional characteristic of the images. Indicates that\n",
            "                        the object is a depiction.\n",
            "  --image_IsInside 1 or 0\n",
            "                        Optional characteristic of the images. Indicates a\n",
            "                        picture taken from the inside of the object.\n",
            "  --multiclasses 0 (default) or 1\n",
            "                        Download different classes separately (0) or together\n",
            "                        (1)\n",
            "  --n_threads [default 20]\n",
            "                        Num of the threads to use\n",
            "  --noLabels            No labels creations\n",
            "  --limit integer number\n",
            "                        Optional limit on number of images to download\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R2ykpd91kdH",
        "colab_type": "text"
      },
      "source": [
        "### Define class names to be referencable\n",
        ">Order of the classes counts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2CfOyguNZE_q",
        "colab": {}
      },
      "source": [
        "classNames = [\"Vehicle registration plate\", \"Car\", \"Person\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFG_ypfZ18E1",
        "colab_type": "text"
      },
      "source": [
        "### Download train, test, validation classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYF-6oVf53jJ",
        "colab_type": "code",
        "outputId": "4e949651-339d-4f6b-8d85-a97a714b321f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 main.py downloader --classes \"Vehicle registration plate\" \"Car\" \"Person\" --type_csv train --multiclasses 0 --limit 5500"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Vehicle registration plate.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...145%, 0 MB, 45527 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 1138 MB, 60289 KB/s, 19 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mVehicle registration plate\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 5368 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 5500 images.\u001b[0m\n",
            "    [INFO] | Download of 5368 images in train.\u001b[0m\n",
            "100% 5368/5368 [43:48<00:00,  2.04it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Vehicle registration plate of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Car.\u001b[0m\n",
            "\n",
            "\u001b[95mCar\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 89465 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 5500 images.\u001b[0m\n",
            "    [INFO] | Download of 5500 images in train.\u001b[0m\n",
            "100% 5500/5500 [41:14<00:00,  2.69it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Car of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Person.\u001b[0m\n",
            "\n",
            "\u001b[95mPerson\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 248384 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 5500 images.\u001b[0m\n",
            "    [INFO] | Download of 5500 images in train.\u001b[0m\n",
            "100% 5500/5500 [40:16<00:00,  1.45it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Person of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rAMPicJImvJ",
        "colab_type": "code",
        "outputId": "02a0c73d-114c-494c-fd2a-7cca41d413f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "!python3 main.py downloader --classes \"Vehicle registration plate\" \"Car\" \"Person\" --type_csv test --multiclasses 0 --limit 500"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Vehicle registration plate.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the test-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 49 MB, 28865 KB/s, 1 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File test-annotations-bbox.csv downloaded into OID/csv_folder/test-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mVehicle registration plate\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 1113 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 500 images in test.\u001b[0m\n",
            "100% 500/500 [04:32<00:00,  1.84it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Vehicle registration plate of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Car.\u001b[0m\n",
            "\n",
            "\u001b[95mCar\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 14663 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 500 images in test.\u001b[0m\n",
            "100% 500/500 [04:33<00:00,  1.97it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Car of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Person.\u001b[0m\n",
            "\n",
            "\u001b[95mPerson\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 19418 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 500 images in test.\u001b[0m\n",
            "100% 500/500 [04:22<00:00,  1.90it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Person of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcloJ-6BIoYK",
        "colab_type": "code",
        "outputId": "26d13dd8-3331-4380-bc83-5eab5bcf82fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "!python3 main.py downloader --classes \"Vehicle registration plate\" \"Car\" \"Person\" --type_csv validation --multiclasses 0 --limit 500"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Vehicle registration plate.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the validation-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 16 MB, 52785 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File validation-annotations-bbox.csv downloaded into OID/csv_folder/validation-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mVehicle registration plate\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 386 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 386 images in validation.\u001b[0m\n",
            "100% 386/386 [03:30<00:00,  1.06it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Vehicle registration plate of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Car.\u001b[0m\n",
            "\n",
            "\u001b[95mCar\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 4900 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 500 images in validation.\u001b[0m\n",
            "100% 500/500 [04:35<00:00,  1.12it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Car of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Person.\u001b[0m\n",
            "\n",
            "\u001b[95mPerson\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 6436 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 500 images in validation.\u001b[0m\n",
            "100% 500/500 [04:19<00:00,  1.92it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Person of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07IlsSmC2Clt",
        "colab_type": "text"
      },
      "source": [
        "##3. Create supplementary files\n",
        ">Create a `txt` file containing the class names, and `tfrecord`s containing the images and their annotations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDopIc4p2n4O",
        "colab_type": "text"
      },
      "source": [
        "### Create class names file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMZ3ezQlYH03",
        "colab_type": "text"
      },
      "source": [
        "#### Create class names `txt` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqCdWeACXr1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createClassTxt(destinationDir, classNames):\n",
        "\n",
        "  os.chdir(destinationDir)\n",
        "  # creating the `classes.txt` file\n",
        "  classesPath = os.path.join(\"classes.txt\")\n",
        "\n",
        "  content = \"\"\n",
        "\n",
        "  # creates a txt file that contains the class names\n",
        "  for i, className in enumerate(classNames):\n",
        "\n",
        "      content = (\n",
        "          content + \n",
        "          \"{0}\\n\".format(className)\n",
        "      )\n",
        "\n",
        "  content = content.strip()\n",
        "\n",
        "  with open(classesPath, \"w\") as f:\n",
        "      f.write(content)\n",
        "\n",
        "  print(\"Class names txt file creation successful. Destination: %s\" %(destinationDir + '/' + classesPath))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wXB0UsTYPBh",
        "colab_type": "text"
      },
      "source": [
        "#### Create class names `pbtxt` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMU8M5FCXvu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createClassPbtxt(destinationDir, classNames):\n",
        "\n",
        "  os.chdir(destinationDir)\n",
        "  # creating the `classes.pbtxt` file\n",
        "  classesPath = os.path.join(\"classes.pbtxt\")\n",
        "\n",
        "  content = \"\"\n",
        "\n",
        "  # creates a pbtxt file that contains the class names\n",
        "  for i, className in enumerate(classNames):\n",
        "\n",
        "      content = (\n",
        "          content + \n",
        "          \"item {{\\n    id: {0}\\n    name: '{1}'\\n }}\\n\\n\".format(i + 1, className)\n",
        "      )\n",
        "\n",
        "  content = content.strip()\n",
        "\n",
        "  with open(classesPath, \"w\") as f:\n",
        "      f.write(content)\n",
        "\n",
        "  print(\"Class names pbtxt file creation successful. Destination: %s\" %(destinationDir + '/' + classesPath))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VHx4n9mXycI",
        "colab_type": "code",
        "outputId": "f789b193-f531-4a7b-dbc7-bb453559a835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "createClassPbtxt(recordsPath, classNames)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class names pbtxt file creation successful. Destination: /content/generated/records/classes.pbtxt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4_FUcGU2_Gl",
        "colab_type": "text"
      },
      "source": [
        "### Create the `tfrecord` files\n",
        ">These files are the inputs of the Tensorflow Object Detection API models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMFpGl_G3aeI",
        "colab_type": "text"
      },
      "source": [
        "#### Create one `tfrecord` from the input parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFa2Tzh0mt1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createRecord(path, imageId, classes, annotations):\n",
        "\n",
        "  image = Image.open(path)\n",
        "  imgWidth, imgHeight = image.size\n",
        "  imgData = tf.gfile.GFile(path, 'rb').read()\n",
        "\n",
        "  xmins = []\n",
        "  xmaxs = []\n",
        "  ymins = []\n",
        "  ymaxs = []\n",
        "  classesText = []\n",
        "  classesInt = []\n",
        "\n",
        "  imageAnnotations = annotations.get_group(imageId)\n",
        "\n",
        "  for _, row in imageAnnotations.loc[imageAnnotations['LabelName'].isin(classes.keys())].iterrows():\n",
        "\n",
        "      xmins.append(row['XMin'])\n",
        "      xmaxs.append(row['XMax'])\n",
        "      ymins.append(row['YMin'])\n",
        "      ymaxs.append(row['YMax'])\n",
        "      classesText.append(row['LabelName'].encode('utf8'))\n",
        "      classesInt.append(classes[row['LabelName']])\n",
        "\n",
        "  tfRecord = tf.train.Example(features=tf.train.Features(feature={\n",
        "      'image/height': dataset_util.int64_feature(imgHeight),\n",
        "      'image/width': dataset_util.int64_feature(imgWidth),\n",
        "      'image/filename': dataset_util.bytes_feature(imageId.encode('utf8')),\n",
        "      'image/source_id': dataset_util.bytes_feature(imageId.encode('utf8')),\n",
        "      'image/encoded': dataset_util.bytes_feature(imgData),\n",
        "      'image/format': dataset_util.bytes_feature(b'jpg'),\n",
        "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "      'image/object/class/text': dataset_util.bytes_list_feature(classesText),\n",
        "      'image/object/class/label': dataset_util.int64_list_feature(classesInt)\n",
        "  }))\n",
        "\n",
        "  return tfRecord"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTmGz4IB-zWJ",
        "colab_type": "text"
      },
      "source": [
        "#### Create a `csv` row from the input parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPzBSRxCWkbA",
        "colab_type": "text"
      },
      "source": [
        "##### Encode list elements as a row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVdARmgcOaiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def appendListAsRow(fileName, list):\n",
        "\n",
        "    # Open file in append mode\n",
        "    with open(fileName, 'a+', newline='') as writeObj:\n",
        "\n",
        "      # Create a writer object from csv module\n",
        "      writer = csv.writer(writeObj)\n",
        "\n",
        "      # Add contents of list as last row in the csv file\n",
        "      writer.writerow(list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm_BPmSFWs1m",
        "colab_type": "text"
      },
      "source": [
        "##### Create `csv` rows of an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uVAP7K2-ume",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createCsvRowsOfImage(path, imageId, classes, annotations):\n",
        "\n",
        "  image = Image.open(path)\n",
        "  imgWidth, imgHeight = image.size\n",
        "  imgData = 1\n",
        "  extension = b'jpg'\n",
        "\n",
        "  imageAnnotations = annotations.get_group(imageId)\n",
        "\n",
        "  CsvRows = []\n",
        "\n",
        "  for _, row in imageAnnotations.loc[imageAnnotations['LabelName'].isin(classes.keys())].iterrows():\n",
        "\n",
        "    CsvRow = []\n",
        "\n",
        "    CsvRow.append(imgHeight)\n",
        "    CsvRow.append(imgWidth)\n",
        "    CsvRow.append(imageId)\n",
        "    CsvRow.append(imageId)\n",
        "    CsvRow.append(imgData)\n",
        "    CsvRow.append(extension)\n",
        "    CsvRow.append(row['XMin'])\n",
        "    CsvRow.append(row['XMax'])\n",
        "    CsvRow.append(row['YMin'])\n",
        "    CsvRow.append(row['YMax'])\n",
        "    CsvRow.append(row['LabelName'].encode('utf8'))\n",
        "    CsvRow.append(classes[row['LabelName']])\n",
        "\n",
        "    CsvRows.append(CsvRow)\n",
        "\n",
        "  return CsvRows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NEhN5zWXPsu",
        "colab_type": "text"
      },
      "source": [
        "#### Add `csv` file header"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_nQw4NKXOCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def csvAddHeader(fileName):\n",
        "\n",
        "  headerRow = []\n",
        "\n",
        "  headerRow.append('imgHeight')\n",
        "  headerRow.append('imgWidth')\n",
        "  headerRow.append('imageId')\n",
        "  headerRow.append('imageId')\n",
        "  headerRow.append('imgData')\n",
        "  headerRow.append('extension')\n",
        "  headerRow.append('XMin')\n",
        "  headerRow.append('XMax')\n",
        "  headerRow.append('YMin')\n",
        "  headerRow.append('YMax')\n",
        "  headerRow.append('LabelName')\n",
        "  headerRow.append('LabelId')\n",
        "\n",
        "  appendListAsRow(fileName, headerRow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaP_6pKd3szr",
        "colab_type": "text"
      },
      "source": [
        "#### Generate the `tfrecord` files from the provided images & annotations\n",
        ">The `numShards` variable serves for deciding how many sub-files must be created in order to speed up processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y31iep6ww_Or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfrecordGenerator(\n",
        "    classesFile,\n",
        "    classDescriptionsFile,\n",
        "    annotationsFile,\n",
        "    imagesDir,\n",
        "    outputFile,\n",
        "    numShards,\n",
        "    csvNeeded,\n",
        "    csvFileName\n",
        "):\n",
        "\n",
        "    classes = list(filter(None, open(classesFile).read().split('\\n')))\n",
        "    classes = {name: idx + 1 for idx, name in enumerate(classes)}\n",
        "    print(f'Classes: {classes}')\n",
        "\n",
        "    classDescriptions = {row[0]: row[1] for _, row in pd.read_csv(classDescriptionsFile, header=None).iterrows()}\n",
        "\n",
        "    annotations = pd.read_csv(annotationsFile)\n",
        "    annotations['LabelName'] = annotations['LabelName'].map(lambda n: classDescriptions[n])\n",
        "    annotations = annotations.groupby('ImageID')\n",
        "\n",
        "    images = tf.gfile.Glob(imagesDir + '/*/*.jpg')\n",
        "    images = map(lambda i: (os.path.basename(i).split('.jpg')[0], i), images)\n",
        "    images = dict(images)\n",
        "    print(f'{len(images)} images found')\n",
        "\n",
        "    with contextlib2.ExitStack() as tfRecordCloseStack:\n",
        "\n",
        "      outputRecords = tf_record_creation_util.open_sharded_output_tfrecords(\n",
        "      tfRecordCloseStack, outputFile, numShards)\n",
        "\n",
        "      index = 0\n",
        "\n",
        "      if(csvNeeded == True):\n",
        "        csvAddHeader(csvFileName)\n",
        "\n",
        "      for imageId, path in images.items():\n",
        "\n",
        "        tfRecord = createRecord(path, imageId, classes, annotations)\n",
        "        outputShardIndex = index % numShards\n",
        "        outputRecords[outputShardIndex].write(tfRecord.SerializeToString())\n",
        "\n",
        "        if(csvNeeded == True):\n",
        "          imageRows = createCsvRowsOfImage(path, imageId, classes, annotations)\n",
        "          for row in imageRows:\n",
        "            appendListAsRow(csvFileName, row)\n",
        "\n",
        "        index += 1\n",
        "\n",
        "    print('TFRecords has been successfully created')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQYorSQ15X5n",
        "colab_type": "text"
      },
      "source": [
        "#### Generate train/test/validation `tfrecord` files\n",
        ">`subsetTypes` contains the subset names, `numShards` contains their corresponding values to be sharded into. More than a few thousand `tfrecord` rows dramatically slow down the process. `numShards=1` means sharding is not needed at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jv5i6EERGpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "34748649-0104-4233-f1d8-8e4d35e6f325"
      },
      "source": [
        "os.chdir(datasetRootPath)\n",
        "\n",
        "# train, test, validation subsets\n",
        "subsetTypes = ['train', 'test', 'validation']\n",
        "numShards = [10, 1, 1]\n",
        "csvNeeded = True\n",
        "csvFileName = \"\"\n",
        "\n",
        "for subsetType, numShard in zip(subsetTypes, numShards):\n",
        "\n",
        "  print(f'***Generating {subsetType} tfrecord files [sharded into {numShard} piece(s)]***')\n",
        "\n",
        "  classesFile = datasetRootPath + '/classes.txt'\n",
        "  classDescriptionsFile = datasetRootPath + '/csv_folder/class-descriptions-boxable.csv'\n",
        "  annotationsFile = datasetRootPath + '/csv_folder/' + subsetType + '-annotations-bbox.csv'\n",
        "  imagesDir = datasetRootPath + '/Dataset/' + subsetType\n",
        "  outputFile = recordsPath + '/' + subsetType + 'Dataset.tfrecord'\n",
        "  csvFileName = csvPath + '/' + subsetType + 'Dataset.csv'\n",
        "\n",
        "  tfrecordGenerator(\n",
        "      classesFile,\n",
        "      classDescriptionsFile,\n",
        "      annotationsFile,\n",
        "      imagesDir,\n",
        "      outputFile,\n",
        "      numShard,\n",
        "      csvNeeded,\n",
        "      csvFileName\n",
        "  )\n",
        "\n",
        "  print('')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***Generating train tfrecord files [sharded into 10 piece(s)]***\n",
            "Classes: {'Vehicle registration plate': 1, 'Car': 2, 'Person': 3}\n",
            "15972 images found\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/dataset_tools/tf_record_creation_util.py:43: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "TFRecords has been successfully created\n",
            "\n",
            "***Generating test tfrecord files [sharded into 1 piece(s)]***\n",
            "Classes: {'Vehicle registration plate': 1, 'Car': 2, 'Person': 3}\n",
            "1440 images found\n",
            "TFRecords has been successfully created\n",
            "\n",
            "***Generating validation tfrecord files [sharded into 1 piece(s)]***\n",
            "Classes: {'Vehicle registration plate': 1, 'Car': 2, 'Person': 3}\n",
            "1342 images found\n",
            "TFRecords has been successfully created\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9ivkngm8kT0",
        "colab_type": "text"
      },
      "source": [
        "##4. Generate dataset\n",
        ">The generated `tfrecord` files need to be zipped and saved to the Drive directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtAaxLiI9IYc",
        "colab_type": "text"
      },
      "source": [
        "###Zip & save `tfrecord` files to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrYaci2wsJxF",
        "colab_type": "code",
        "outputId": "82c40057-6f41-4dc0-a51b-f168aaae3ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "outputFileName = \"datasetRecords\"\n",
        "os.chdir(localPath)\n",
        "shutil.make_archive(outputFileName, 'zip', recordsPath)\n",
        "shutil.move(localPath + '/' + outputFileName + '.zip', dataPath)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Machine Learning/License plate detection/data/datasetRecords.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOYsm0uGVIhI",
        "colab_type": "text"
      },
      "source": [
        "###Zip & save `csv` files to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UYd6ThDVHkd",
        "colab_type": "code",
        "outputId": "84c72a03-af1c-4464-dd52-aea4aab3684b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "outputFileName = \"datasetCsvs\"\n",
        "os.chdir(localPath)\n",
        "shutil.make_archive(outputFileName, 'zip', csvPath)\n",
        "shutil.move(localPath + '/' + outputFileName + '.zip', dataPath)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Machine Learning/License plate detection/data/datasetCsvs.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkfc8ts89ZB8",
        "colab_type": "text"
      },
      "source": [
        "### How to use the sharded dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNOd_QH0f4bB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_record_input_reader {\n",
        "  input_path: \"/path/to/trainDataset.tfrecord-?????-of-00010\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aqu3q4YLWOfc",
        "colab_type": "text"
      },
      "source": [
        "##Force garbage collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oB7Dol-TuNU",
        "colab_type": "code",
        "outputId": "3f9136b4-3a75-47fb-a2d5-970378b66e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "759"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}